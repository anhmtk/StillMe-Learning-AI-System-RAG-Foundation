name: Shadow Inventory & Quarantine CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:

jobs:
  inventory-scan:
    runs-on: ubuntu-latest
    name: Repository Inventory Scan
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for git analysis
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
    
    - name: Run Primary Inventory
      run: |
        python tools/repo_inventory.py --mode primary --with-hash
    
    - name: Run Excluded Inventory
      run: |
        python tools/repo_inventory.py --mode excluded
    
    - name: Find Deletion Candidates
      run: |
        python tools/find_candidates.py
    
    - name: Archive Inventory Reports
      uses: actions/upload-artifact@v3
      with:
        name: inventory-reports
        path: |
          reports/primary_inventory.csv
          reports/primary_large_files.csv
          reports/primary_dep_grraph.json
          reports/primary_summary.json
          reports/excluded_inventory.csv
          reports/excluded_large_files.csv
          reports/deletion_candidates.md
          reports/deletion_candidates.csv
        retention-days: 30

  quarantine-test:
    runs-on: ubuntu-latest
    name: Quarantine Test (LOW risk only)
    needs: inventory-scan
    if: github.event_name == 'pull_request'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
    
    - name: Download Inventory Reports
      uses: actions/download-artifact@v3
      with:
        name: inventory-reports
        path: reports/
    
    - name: Run Unit Tests (Before Quarantine)
      run: |
        python -m pytest tests/ -v --tb=short --maxfail=5
    
    - name: Quarantine LOW Risk Files
      run: |
        python tools/quarantine_move.py --action quarantine --risk LOW --dry-run
        # Note: In real CI, we might want to actually quarantine for testing
        # python tools/quarantine_move.py --action quarantine --risk LOW
    
    - name: Run Unit Tests (After Quarantine)
      run: |
        python -m pytest tests/ -v --tb=short --maxfail=5
    
    - name: Restore Quarantined Files
      run: |
        python tools/restore_from_graveyard.py
    
    - name: Run Unit Tests (After Restore)
      run: |
        python -m pytest tests/ -v --tb=short --maxfail=5

  inventory-summary:
    runs-on: ubuntu-latest
    name: Inventory Summary
    needs: [inventory-scan, quarantine-test]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-test.txt
    
    - name: Download Inventory Reports
      uses: actions/download-artifact@v3
      with:
        name: inventory-reports
        path: reports/
    
    - name: Generate Summary
      run: |
        python -c "
        import json
        import csv
        from pathlib import Path
        
        # Load primary summary
        summary_path = Path('reports/primary_summary.json')
        if summary_path.exists():
            with open(summary_path, 'r') as f:
                summary = json.load(f)
            
            print('ğŸ“Š Repository Inventory Summary')
            print('=' * 50)
            print(f'Total files: {summary.get(\"total_files\", 0)}')
            print(f'Total size: {summary.get(\"total_size_mb\", 0):.1f} MB')
            print(f'Unreferenced files: {summary.get(\"unreferenced_files\", 0)}')
            print(f'Binary files: {summary.get(\"binary_files\", 0)}')
            
            print('\nBy type:')
            for file_type, count in summary.get('by_type', {}).items():
                print(f'  {file_type}: {count}')
            
            print('\nBy size:')
            for size_cat, count in summary.get('by_size', {}).items():
                print(f'  {size_cat}: {count}')
        
        # Load deletion candidates
        candidates_path = Path('reports/deletion_candidates.csv')
        if candidates_path.exists():
            with open(candidates_path, 'r') as f:
                reader = csv.DictReader(f)
                candidates = list(reader)
            
            print(f'\nğŸ—‘ï¸ Deletion Candidates: {len(candidates)}')
            
            by_risk = {}
            by_category = {}
            
            for candidate in candidates:
                risk = candidate['risk']
                category = candidate['category']
                
                by_risk[risk] = by_risk.get(risk, 0) + 1
                by_category[category] = by_category.get(category, 0) + 1
            
            print('By risk:')
            for risk, count in by_risk.items():
                print(f'  {risk}: {count}')
            
            print('By category:')
            for category, count in by_category.items():
                print(f'  {category}: {count}')
        "
    
    - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Read summary data
          let summary = '';
          try {
            const summaryPath = path.join('reports', 'primary_summary.json');
            if (fs.existsSync(summaryPath)) {
              const data = JSON.parse(fs.readFileSync(summaryPath, 'utf8'));
              summary = `ğŸ“Š **Repository Inventory Summary**\n\n`;
              summary += `- Total files: ${data.total_files || 0}\n`;
              summary += `- Total size: ${(data.total_size_mb || 0).toFixed(1)} MB\n`;
              summary += `- Unreferenced files: ${data.unreferenced_files || 0}\n`;
              summary += `- Binary files: ${data.binary_files || 0}\n\n`;
              
              summary += `**By type:**\n`;
              for (const [type, count] of Object.entries(data.by_type || {})) {
                summary += `- ${type}: ${count}\n`;
              }
            }
          } catch (error) {
            summary = 'âŒ Error reading inventory summary\n';
          }
          
          // Read deletion candidates
          let candidates = '';
          try {
            const candidatesPath = path.join('reports', 'deletion_candidates.csv');
            if (fs.existsSync(candidatesPath)) {
              const csv = fs.readFileSync(candidatesPath, 'utf8');
              const lines = csv.split('\n').filter(line => line.trim());
              const candidates_count = lines.length - 1; // Subtract header
              
              candidates = `\nğŸ—‘ï¸ **Deletion Candidates: ${candidates_count}**\n\n`;
              candidates += `See [deletion_candidates.md](https://github.com/${context.repo.owner}/${context.repo.repo}/blob/${context.sha}/reports/deletion_candidates.md) for details.\n`;
            }
          } catch (error) {
            candidates = '\nâŒ Error reading deletion candidates\n';
          }
          
          const comment = `## ğŸ” Repository Inventory Report\n\n${summary}${candidates}`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

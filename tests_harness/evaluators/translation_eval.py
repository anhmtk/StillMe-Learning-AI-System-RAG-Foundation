#!/usr/bin/env python3
"""
TranslationEval - ÄÃ¡nh giÃ¡ kháº£ nÄƒng dá»‹ch thuáº­t cá»§a StillMe AI

Kiá»ƒm tra:
- PhÃ¡t hiá»‡n ngÃ´n ngá»¯ chÃ­nh xÃ¡c
- Dá»‹ch Ä‘Ãºng nghÄ©a vÃ  ngá»¯ cáº£nh
- TÃ­ch há»£p vá»›i Gemma/NLLB local
- Báº£o toÃ n code blocks vÃ  URLs
- ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng dá»‹ch thuáº­t
"""

import json
import logging
import re
from dataclasses import asdict, dataclass
from datetime import datetime
from typing import Any, Optional

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class TranslationScore:
    """Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ dá»‹ch thuáº­t"""

    language_detection: float  # 0-1: phÃ¡t hiá»‡n ngÃ´n ngá»¯
    translation_accuracy: float  # 0-1: Ä‘á»™ chÃ­nh xÃ¡c dá»‹ch
    context_preservation: float  # 0-1: báº£o toÃ n ngá»¯ cáº£nh
    code_preservation: float  # 0-1: báº£o toÃ n code blocks
    url_preservation: float  # 0-1: báº£o toÃ n URLs
    overall_translation_score: float  # 0-1: Ä‘iá»ƒm dá»‹ch thuáº­t tá»•ng

    def to_dict(self) -> dict[str, Any]:
        return asdict(self)


class TranslationEval:
    """Evaluator cho kháº£ nÄƒng dá»‹ch thuáº­t"""

    def __init__(self):
        self.logger = logger

        # Language detection patterns
        self.language_patterns = {
            "vietnamese": [
                r"[Ã Ã¡áº¡áº£Ã£Ã¢áº§áº¥áº­áº©áº«Äƒáº±áº¯áº·áº³áºµÃ¨Ã©áº¹áº»áº½Ãªá»áº¿á»‡á»ƒá»…Ã¬Ã­á»‹á»‰Ä©Ã²Ã³á»á»ÃµÃ´á»“á»‘á»™á»•á»—Æ¡á»á»›á»£á»Ÿá»¡Ã¹Ãºá»¥á»§Å©Æ°á»«á»©á»±á»­á»¯á»³Ã½á»µá»·á»¹Ä‘]",
                r"\b(xin\s+chÃ o|tÃ´i|báº¡n|mÃ¬nh|anh|chá»‹|em|bÃ¡c|cÃ´|chÃº|dÃ¬|cáº­u|má»£)\b",
                r"\b(hÃ´m\s+nay|ngÃ y\s+mai|hÃ´m\s+qua|tuáº§n\s+nÃ y|thÃ¡ng\s+nÃ y)\b",
                r"\b(cáº£m\s+Æ¡n|xin\s+lá»—i|khÃ´ng\s+cÃ³\s+gÃ¬|khÃ´ng\s+sao)\b",
            ],
            "english": [
                r"\b(hello|hi|good\s+morning|good\s+afternoon|good\s+evening)\b",
                r"\b(I|you|he|she|it|we|they|me|him|her|us|them)\b",
                r"\b(today|tomorrow|yesterday|this\s+week|this\s+month)\b",
                r"\b(thank\s+you|sorry|excuse\s+me|you\'re\s+welcome)\b",
            ],
            "chinese": [
                r"[ä¸€-é¾¯]",
                r"\b(ä½ å¥½|æ‚¨å¥½|è°¢è°¢|å¯¹ä¸èµ·|æ²¡å…³ç³»)\b",
                r"\b(ä»Šå¤©|æ˜å¤©|æ˜¨å¤©|è¿™å‘¨|è¿™ä¸ªæœˆ)\b",
            ],
            "japanese": [
                r"[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠ]",
                r"\b(ã“ã‚“ã«ã¡ã¯|ã‚ã‚ŠãŒã¨ã†|ã™ã¿ã¾ã›ã‚“|å¤§ä¸ˆå¤«)\b",
                r"\b(ä»Šæ—¥|æ˜æ—¥|æ˜¨æ—¥|ä»Šé€±|ä»Šæœˆ)\b",
            ],
            "korean": [
                r"[ê°€-í£]",
                r"\b(ì•ˆë…•í•˜ì„¸ìš”|ê°ì‚¬í•©ë‹ˆë‹¤|ì£„ì†¡í•©ë‹ˆë‹¤|ê´œì°®ìŠµë‹ˆë‹¤)\b",
                r"\b(ì˜¤ëŠ˜|ë‚´ì¼|ì–´ì œ|ì´ë²ˆ\s+ì£¼|ì´ë²ˆ\s+ë‹¬)\b",
            ],
        }

        # Code block patterns
        self.code_patterns = [
            r"```[\s\S]*?```",  # Markdown code blocks
            r"`[^`]+`",  # Inline code
            r"<code>[\s\S]*?</code>",  # HTML code tags
            r"<pre>[\s\S]*?</pre>",  # HTML pre tags
        ]

        # URL patterns
        self.url_patterns = [
            r"https?://[^\s]+",
            r"www\.[^\s]+",
            r"[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}",
            r"ftp://[^\s]+",
        ]

        # Translation quality indicators
        self.quality_indicators = {
            "good": [
                r"\b(accurate|correct|proper|appropriate|suitable)\b",
                r"\b(chÃ­nh\s+xÃ¡c|Ä‘Ãºng|phÃ¹\s+há»£p|thÃ­ch\s+há»£p)\b",
            ],
            "bad": [
                r"\b(wrong|incorrect|inappropriate|unsuitable|inaccurate)\b",
                r"\b(sai|khÃ´ng\s+Ä‘Ãºng|khÃ´ng\s+phÃ¹\s+há»£p|khÃ´ng\s+thÃ­ch\s+há»£p)\b",
            ],
        }

        # Common translation pairs for testing
        self.translation_pairs = {
            "vietnamese_english": {
                "xin chÃ o": "hello",
                "cáº£m Æ¡n": "thank you",
                "xin lá»—i": "sorry",
                "khÃ´ng cÃ³ gÃ¬": "you're welcome",
                "hÃ´m nay": "today",
                "ngÃ y mai": "tomorrow",
                "hÃ´m qua": "yesterday",
            },
            "english_vietnamese": {
                "hello": "xin chÃ o",
                "thank you": "cáº£m Æ¡n",
                "sorry": "xin lá»—i",
                "you're welcome": "khÃ´ng cÃ³ gÃ¬",
                "today": "hÃ´m nay",
                "tomorrow": "ngÃ y mai",
                "yesterday": "hÃ´m qua",
            },
        }

    def evaluate(
        self,
        response: str,
        user_input: str = "",
        expected_language: Optional[str] = None,
        source_language: Optional[str] = None,
    ) -> TranslationScore:
        """
        ÄÃ¡nh giÃ¡ kháº£ nÄƒng dá»‹ch thuáº­t cá»§a response

        Args:
            response: AI response cáº§n Ä‘Ã¡nh giÃ¡
            user_input: User input gá»‘c (optional)
            expected_language: NgÃ´n ngá»¯ mong Ä‘á»£i (optional)
            source_language: NgÃ´n ngá»¯ nguá»“n (optional)

        Returns:
            TranslationScore: Káº¿t quáº£ Ä‘Ã¡nh giÃ¡ dá»‹ch thuáº­t
        """
        try:
            self.logger.info(
                f"ğŸ” Evaluating translation for response: {response[:100]}..."
            )

            # 1. ÄÃ¡nh giÃ¡ phÃ¡t hiá»‡n ngÃ´n ngá»¯
            detection_score = self._evaluate_language_detection(
                response, expected_language
            )

            # 2. ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c dá»‹ch
            accuracy_score = self._evaluate_translation_accuracy(
                response, user_input, source_language
            )

            # 3. ÄÃ¡nh giÃ¡ báº£o toÃ n ngá»¯ cáº£nh
            context_score = self._evaluate_context_preservation(response, user_input)

            # 4. ÄÃ¡nh giÃ¡ báº£o toÃ n code blocks
            code_score = self._evaluate_code_preservation(response, user_input)

            # 5. ÄÃ¡nh giÃ¡ báº£o toÃ n URLs
            url_score = self._evaluate_url_preservation(response, user_input)

            # 6. TÃ­nh Ä‘iá»ƒm dá»‹ch thuáº­t tá»•ng
            overall_score = (
                detection_score * 0.2
                + accuracy_score * 0.3
                + context_score * 0.2
                + code_score * 0.15
                + url_score * 0.15
            )

            result = TranslationScore(
                language_detection=detection_score,
                translation_accuracy=accuracy_score,
                context_preservation=context_score,
                code_preservation=code_score,
                url_preservation=url_score,
                overall_translation_score=overall_score,
            )

            self.logger.info(
                f"âœ… Translation evaluation completed. Overall score: {overall_score:.3f}"
            )
            return result

        except Exception as e:
            self.logger.error(f"âŒ Translation evaluation failed: {e}")
            return TranslationScore(0, 0, 0, 0, 0, 0)

    def _evaluate_language_detection(
        self, response: str, expected_language: Optional[str] = None
    ) -> float:
        """ÄÃ¡nh giÃ¡ phÃ¡t hiá»‡n ngÃ´n ngá»¯"""
        try:
            score = 0.0
            total_checks = 0

            # Detect language in response
            detected_language = self._detect_language(response)

            if expected_language:
                if detected_language == expected_language:
                    score += 0.6  # Correct language detection
                else:
                    score += 0.2  # Wrong language detection
                total_checks += 1
            else:
                # No expected language, check if detection is consistent
                if detected_language:
                    score += 0.5  # Language detected
                total_checks += 1

            # Check for language consistency
            if detected_language:
                # Check if response is mostly in the detected language
                language_ratio = self._calculate_language_ratio(
                    response, detected_language
                )
                if language_ratio > 0.7:
                    score += 0.3  # High consistency
                elif language_ratio > 0.5:
                    score += 0.2  # Medium consistency
                else:
                    score += 0.1  # Low consistency
                total_checks += 1

            # Check for mixed language handling
            mixed_language_count = self._count_mixed_languages(response)
            if mixed_language_count <= 1:
                score += 0.1  # Good language separation
            total_checks += 1

            return min(score / max(total_checks, 1), 1.0)

        except Exception as e:
            self.logger.error(f"Error evaluating language detection: {e}")
            return 0.0

    def _evaluate_translation_accuracy(
        self, response: str, user_input: str, source_language: Optional[str] = None
    ) -> float:
        """ÄÃ¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c dá»‹ch"""
        try:
            score = 0.0
            total_checks = 0

            # Check for common translation pairs
            if source_language and user_input:
                detected_source = self._detect_language(user_input)
                detected_target = self._detect_language(response)

                if detected_source and detected_target:
                    # Check if translation direction is correct
                    if detected_source != detected_target:
                        score += 0.4  # Translation occurred
                        total_checks += 1

                        # Check for common translation pairs
                        translation_score = self._check_translation_pairs(
                            user_input, response, detected_source, detected_target
                        )
                        score += translation_score * 0.4
                        total_checks += 1
                    else:
                        score += 0.2  # No translation needed
                        total_checks += 1

            # Check for translation quality indicators
            quality_score = self._check_translation_quality(response)
            score += quality_score * 0.2
            total_checks += 1

            return min(score / max(total_checks, 1), 1.0)

        except Exception as e:
            self.logger.error(f"Error evaluating translation accuracy: {e}")
            return 0.0

    def _evaluate_context_preservation(self, response: str, user_input: str) -> float:
        """ÄÃ¡nh giÃ¡ báº£o toÃ n ngá»¯ cáº£nh"""
        try:
            score = 0.0
            total_checks = 0

            # Check if response maintains the same intent
            if user_input:
                input_intent = self._extract_intent(user_input)
                response_intent = self._extract_intent(response)

                if input_intent and response_intent:
                    if input_intent == response_intent:
                        score += 0.5  # Intent preserved
                    else:
                        score += 0.2  # Intent partially preserved
                    total_checks += 1

            # Check for context keywords preservation
            context_keywords = self._extract_context_keywords(user_input)
            if context_keywords:
                preserved_keywords = 0
                for keyword in context_keywords:
                    if keyword.lower() in response.lower():
                        preserved_keywords += 1

                preservation_ratio = preserved_keywords / len(context_keywords)
                score += preservation_ratio * 0.3
                total_checks += 1

            # Check for temporal context preservation
            temporal_indicators = [
                "hÃ´m nay",
                "today",
                "ngÃ y mai",
                "tomorrow",
                "hÃ´m qua",
                "yesterday",
            ]
            temporal_preserved = any(
                indicator in user_input.lower() and indicator in response.lower()
                for indicator in temporal_indicators
            )
            if temporal_preserved:
                score += 0.2
            total_checks += 1

            return min(score / max(total_checks, 1), 1.0)

        except Exception as e:
            self.logger.error(f"Error evaluating context preservation: {e}")
            return 0.0

    def _evaluate_code_preservation(self, response: str, user_input: str) -> float:
        """ÄÃ¡nh giÃ¡ báº£o toÃ n code blocks"""
        try:
            score = 0.0
            total_checks = 0

            # Extract code blocks from input
            input_code_blocks = []
            for pattern in self.code_patterns:
                input_code_blocks.extend(re.findall(pattern, user_input, re.IGNORECASE))

            if input_code_blocks:
                # Check if code blocks are preserved in response
                preserved_blocks = 0
                for block in input_code_blocks:
                    if block in response:
                        preserved_blocks += 1

                preservation_ratio = preserved_blocks / len(input_code_blocks)
                score += preservation_ratio * 0.6
                total_checks += 1

                # Check for code block formatting
                if preservation_ratio > 0:
                    score += 0.2  # Code blocks preserved
                total_checks += 1
            else:
                # No code blocks to preserve
                score += 0.8
                total_checks += 1

            # Check for inline code preservation
            inline_code_pattern = r"`[^`]+`"
            input_inline_code = re.findall(inline_code_pattern, user_input)
            if input_inline_code:
                preserved_inline = 0
                for code in input_inline_code:
                    if code in response:
                        preserved_inline += 1

                if preserved_inline > 0:
                    score += 0.2
                total_checks += 1

            return min(score / max(total_checks, 1), 1.0)

        except Exception as e:
            self.logger.error(f"Error evaluating code preservation: {e}")
            return 0.0

    def _evaluate_url_preservation(self, response: str, user_input: str) -> float:
        """ÄÃ¡nh giÃ¡ báº£o toÃ n URLs"""
        try:
            score = 0.0
            total_checks = 0

            # Extract URLs from input
            input_urls = []
            for pattern in self.url_patterns:
                input_urls.extend(re.findall(pattern, user_input, re.IGNORECASE))

            if input_urls:
                # Check if URLs are preserved in response
                preserved_urls = 0
                for url in input_urls:
                    if url in response:
                        preserved_urls += 1

                preservation_ratio = preserved_urls / len(input_urls)
                score += preservation_ratio * 0.8
                total_checks += 1

                # Check for URL formatting
                if preservation_ratio > 0:
                    score += 0.2  # URLs preserved
                total_checks += 1
            else:
                # No URLs to preserve
                score += 1.0
                total_checks += 1

            return min(score / max(total_checks, 1), 1.0)

        except Exception as e:
            self.logger.error(f"Error evaluating URL preservation: {e}")
            return 0.0

    def _detect_language(self, text: str) -> Optional[str]:
        """PhÃ¡t hiá»‡n ngÃ´n ngá»¯ cá»§a text"""
        try:
            language_scores = {}

            for language, patterns in self.language_patterns.items():
                score = 0
                for pattern in patterns:
                    matches = len(re.findall(pattern, text, re.IGNORECASE))
                    score += matches
                language_scores[language] = score

            if language_scores:
                return max(language_scores, key=language_scores.get)
            return None

        except Exception as e:
            self.logger.error(f"Error detecting language: {e}")
            return None

    def _calculate_language_ratio(self, text: str, language: str) -> float:
        """TÃ­nh tá»· lá»‡ ngÃ´n ngá»¯ trong text"""
        try:
            if language not in self.language_patterns:
                return 0.0

            total_chars = len(text)
            if total_chars == 0:
                return 0.0

            language_chars = 0
            for pattern in self.language_patterns[language]:
                matches = re.findall(pattern, text, re.IGNORECASE)
                language_chars += sum(len(match) for match in matches)

            return language_chars / total_chars

        except Exception as e:
            self.logger.error(f"Error calculating language ratio: {e}")
            return 0.0

    def _count_mixed_languages(self, text: str) -> int:
        """Äáº¿m sá»‘ ngÃ´n ngá»¯ khÃ¡c nhau trong text"""
        try:
            detected_languages = set()
            for language, patterns in self.language_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, text, re.IGNORECASE):
                        detected_languages.add(language)
                        break

            return len(detected_languages)

        except Exception as e:
            self.logger.error(f"Error counting mixed languages: {e}")
            return 0

    def _check_translation_pairs(
        self, input_text: str, response_text: str, source_lang: str, target_lang: str
    ) -> float:
        """Kiá»ƒm tra cÃ¡c cáº·p dá»‹ch thuáº­t phá»• biáº¿n"""
        try:
            score = 0.0
            total_pairs = 0

            # Get translation pairs for the language combination
            pair_key = f"{source_lang}_{target_lang}"
            if pair_key in self.translation_pairs:
                pairs = self.translation_pairs[pair_key]
                for source, target in pairs.items():
                    if (
                        source.lower() in input_text.lower()
                        and target.lower() in response_text.lower()
                    ):
                        score += 1.0
                    total_pairs += 1

            if total_pairs > 0:
                return score / total_pairs
            return 0.0

        except Exception as e:
            self.logger.error(f"Error checking translation pairs: {e}")
            return 0.0

    def _check_translation_quality(self, response: str) -> float:
        """Kiá»ƒm tra cháº¥t lÆ°á»£ng dá»‹ch thuáº­t"""
        try:
            score = 0.0
            total_checks = 0

            # Check for good quality indicators
            good_count = sum(
                len(re.findall(pattern, response, re.IGNORECASE))
                for pattern in self.quality_indicators["good"]
            )
            if good_count > 0:
                score += 0.5
            total_checks += 1

            # Check for bad quality indicators
            bad_count = sum(
                len(re.findall(pattern, response, re.IGNORECASE))
                for pattern in self.quality_indicators["bad"]
            )
            if bad_count == 0:
                score += 0.3
            total_checks += 1

            # Check for translation metadata
            if "translation" in response.lower() or "dá»‹ch" in response.lower():
                score += 0.2
            total_checks += 1

            return min(score / max(total_checks, 1), 1.0)

        except Exception as e:
            self.logger.error(f"Error checking translation quality: {e}")
            return 0.0

    def _extract_intent(self, text: str) -> Optional[str]:
        """TrÃ­ch xuáº¥t Ã½ Ä‘á»‹nh tá»« text"""
        try:
            text_lower = text.lower()

            if any(word in text_lower for word in ["hello", "hi", "xin chÃ o", "chÃ o"]):
                return "greeting"
            elif any(word in text_lower for word in ["thank", "cáº£m Æ¡n", "thanks"]):
                return "thanks"
            elif any(word in text_lower for word in ["sorry", "xin lá»—i", "excuse"]):
                return "apology"
            elif any(word in text_lower for word in ["help", "giÃºp", "assist"]):
                return "help_request"
            elif any(word in text_lower for word in ["question", "cÃ¢u há»i", "ask"]):
                return "question"
            else:
                return "general"

        except Exception as e:
            self.logger.error(f"Error extracting intent: {e}")
            return None

    def _extract_context_keywords(self, text: str) -> list[str]:
        """TrÃ­ch xuáº¥t tá»« khÃ³a ngá»¯ cáº£nh"""
        try:
            keywords = []

            # Time-related keywords
            time_keywords = [
                "hÃ´m nay",
                "today",
                "ngÃ y mai",
                "tomorrow",
                "hÃ´m qua",
                "yesterday",
            ]
            for keyword in time_keywords:
                if keyword in text.lower():
                    keywords.append(keyword)

            # Location-related keywords
            location_keywords = ["á»Ÿ Ä‘Ã¢y", "here", "á»Ÿ Ä‘Ã³", "there", "nÆ¡i", "place"]
            for keyword in location_keywords:
                if keyword in text.lower():
                    keywords.append(keyword)

            # Person-related keywords
            person_keywords = ["tÃ´i", "I", "báº¡n", "you", "anh", "chá»‹", "em"]
            for keyword in person_keywords:
                if keyword in text.lower():
                    keywords.append(keyword)

            return keywords

        except Exception as e:
            self.logger.error(f"Error extracting context keywords: {e}")
            return []

    def batch_evaluate(self, responses: list[dict[str, Any]]) -> list[TranslationScore]:
        """ÄÃ¡nh giÃ¡ hÃ ng loáº¡t responses"""
        results = []

        for i, item in enumerate(responses):
            try:
                response = item.get("response", "")
                user_input = item.get("user_input", "")
                expected_language = item.get("expected_language")
                source_language = item.get("source_language")

                score = self.evaluate(
                    response, user_input, expected_language, source_language
                )
                results.append(score)

                self.logger.info(f"âœ… Evaluated response {i+1}/{len(responses)}")

            except Exception as e:
                self.logger.error(f"âŒ Failed to evaluate response {i+1}: {e}")
                results.append(TranslationScore(0, 0, 0, 0, 0, 0))

        return results

    def generate_report(self, scores: list[TranslationScore]) -> dict[str, Any]:
        """Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p"""
        try:
            if not scores:
                return {"error": "No scores provided"}

            # Calculate statistics
            total_scores = len(scores)
            avg_detection = sum(s.language_detection for s in scores) / total_scores
            avg_accuracy = sum(s.translation_accuracy for s in scores) / total_scores
            avg_context = sum(s.context_preservation for s in scores) / total_scores
            avg_code = sum(s.code_preservation for s in scores) / total_scores
            avg_url = sum(s.url_preservation for s in scores) / total_scores
            avg_overall = (
                sum(s.overall_translation_score for s in scores) / total_scores
            )

            # Find best and worst scores
            best_score = max(scores, key=lambda s: s.overall_translation_score)
            worst_score = min(scores, key=lambda s: s.overall_translation_score)

            report = {
                "timestamp": datetime.now().isoformat(),
                "total_responses": total_scores,
                "average_scores": {
                    "language_detection": round(avg_detection, 3),
                    "translation_accuracy": round(avg_accuracy, 3),
                    "context_preservation": round(avg_context, 3),
                    "code_preservation": round(avg_code, 3),
                    "url_preservation": round(avg_url, 3),
                    "overall_translation": round(avg_overall, 3),
                },
                "best_score": {
                    "overall_translation": round(
                        best_score.overall_translation_score, 3
                    ),
                    "language_detection": round(best_score.language_detection, 3),
                    "translation_accuracy": round(best_score.translation_accuracy, 3),
                },
                "worst_score": {
                    "overall_translation": round(
                        worst_score.overall_translation_score, 3
                    ),
                    "language_detection": round(worst_score.language_detection, 3),
                    "translation_accuracy": round(worst_score.translation_accuracy, 3),
                },
                "translation_distribution": {
                    "excellent": len(
                        [s for s in scores if s.overall_translation_score >= 0.8]
                    ),
                    "good": len(
                        [s for s in scores if 0.6 <= s.overall_translation_score < 0.8]
                    ),
                    "fair": len(
                        [s for s in scores if 0.4 <= s.overall_translation_score < 0.6]
                    ),
                    "poor": len(
                        [s for s in scores if s.overall_translation_score < 0.4]
                    ),
                },
            }

            return report

        except Exception as e:
            self.logger.error(f"Error generating report: {e}")
            return {"error": str(e)}


# Example usage
if __name__ == "__main__":
    # Test TranslationEval
    evaluator = TranslationEval()

    # Test responses
    test_responses = [
        {
            "response": "Xin chÃ o anh! Em lÃ  StillMe AI. Ráº¥t vui Ä‘Æ°á»£c gáº·p anh! Em cÃ³ thá»ƒ giÃºp gÃ¬ cho anh hÃ´m nay?",
            "user_input": "Hello StillMe",
            "expected_language": "vietnamese",
            "source_language": "english",
        },
        {
            "response": "Hello! I'm StillMe AI. Nice to meet you! How can I help you today?",
            "user_input": "Xin chÃ o StillMe",
            "expected_language": "english",
            "source_language": "vietnamese",
        },
    ]

    # Evaluate
    scores = evaluator.batch_evaluate(test_responses)

    # Generate report
    report = evaluator.generate_report(scores)

    print("ğŸŒ TranslationEval Test Results:")
    print(json.dumps(report, indent=2, ensure_ascii=False))

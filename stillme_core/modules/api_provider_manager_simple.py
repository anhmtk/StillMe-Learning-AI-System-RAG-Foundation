#!/usr/bin/env python3
"""
ðŸ”Œ API PROVIDER MANAGER - SIMPLE VERSION
ðŸ”Œ API PROVIDER MANAGER - PHIÃŠN Báº¢N ÄÆ N GIáº¢N

PURPOSE / Má»¤C ÄÃCH:
- Simple API provider manager without complex dependencies
- Quáº£n lÃ½ API provider Ä‘Æ¡n giáº£n khÃ´ng cÃ³ dependencies phá»©c táº¡p
- Handles AI model routing and responses
- Xá»­ lÃ½ routing model AI vÃ  pháº£n há»“i
- Provides fallback responses when external APIs fail
- Cung cáº¥p pháº£n há»“i fallback khi external APIs tháº¥t báº¡i
"""

import logging
import os
import time
from typing import Any, Dict, List, Optional

# Initialize logger
logger = logging.getLogger("StillMe.APIProvider")

class UnifiedAPIManager:
    """Simple API provider manager with fallback responses"""

    def __init__(self):
        self.logger = logger
        self.model_preferences = ["gemma2:2b", "deepseek-coder:6.7b", "deepseek-chat"]
        self.translation_core_lang = os.getenv("TRANSLATION_CORE_LANG", "en")
        self.translator_priority = os.getenv("TRANSLATOR_PRIORITY", "gemma,nllb")
        self.nllb_model_name = os.getenv("NLLB_MODEL_NAME", "facebook/nllb-200-distilled-600M")

        # Initialize complexity analyzer
        self.complexity_analyzer = ComplexityAnalyzer()

        self.logger.info("âœ… UnifiedAPIManager initialized (simple mode)")

    def get_response(self, prompt: str, model: Optional[str] = None) -> str:
        """Get AI response from appropriate model"""
        try:
            # Choose model based on complexity
            selected_model = model or self.choose_model(prompt)
            self.logger.info(f"ðŸŽ¯ Selected model: {selected_model}")

            # Generate response based on model
            if selected_model == "gemma2:2b":
                return self._generate_simple_response(prompt)
            elif selected_model == "deepseek-coder:6.7b":
                return self._generate_coding_response(prompt)
            elif selected_model == "deepseek-chat":
                return self._generate_complex_response(prompt)
            else:
                return self._generate_fallback_response(prompt)

        except Exception as e:
            self.logger.error(f"âŒ Error getting response: {e}")
            return self._generate_fallback_response(prompt)

    def choose_model(self, prompt: str) -> str:
        """Choose appropriate model based on prompt complexity"""
        try:
            complexity_score = self.complexity_analyzer.analyze_complexity(prompt)
            self.logger.info(f"ðŸ§  Complexity Analysis: {complexity_score:.2f}")

            # High complexity (score >= 0.7) â†’ use cloud model
            if complexity_score >= 0.7:
                return "deepseek-chat"

            # Medium complexity (score >= 0.4) â†’ use local coder model
            elif complexity_score >= 0.4:
                return "deepseek-coder:6.7b"

            # Low complexity â†’ use simple model
            else:
                return "gemma2:2b"

        except Exception as e:
            self.logger.warning(f"âš ï¸ Complexity analysis failed: {e}")
            return "gemma2:2b"  # Default fallback

    def _generate_simple_response(self, prompt: str) -> str:
        """Generate simple response for basic questions"""
        prompt_lower = prompt.lower()

        if any(word in prompt_lower for word in ["hello", "hi", "xin chÃ o", "chÃ o"]):
            return "Xin chÃ o! TÃ´i lÃ  StillMe AI. Ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n!"

        elif "test" in prompt_lower:
            return "âœ… Test thÃ nh cÃ´ng! StillMe AI Ä‘ang hoáº¡t Ä‘á»™ng bÃ¬nh thÆ°á»ng."

        elif any(word in prompt_lower for word in ["status", "tráº¡ng thÃ¡i"]):
            return f"ðŸŸ¢ StillMe AI Status: ONLINE\nâ° Time: {time.strftime('%H:%M:%S')}\nðŸ¤– Model: Simple Mode"

        else:
            return f"TÃ´i hiá»ƒu báº¡n Ä‘ang há»i vá»: '{prompt}'. ÄÃ¢y lÃ  cÃ¢u tráº£ lá»i Ä‘Æ¡n giáº£n tá»« StillMe AI."

    def _generate_coding_response(self, prompt: str) -> str:
        """Generate coding response for programming questions"""
        prompt_lower = prompt.lower()

        if any(word in prompt_lower for word in ["python", "code", "láº­p trÃ¬nh"]):
            return "ÄÃ¢y lÃ  cÃ¢u tráº£ lá»i vá» láº­p trÃ¬nh tá»« StillMe AI. TÃ´i cÃ³ thá»ƒ giÃºp báº¡n vá»›i Python, JavaScript, vÃ  nhiá»u ngÃ´n ngá»¯ khÃ¡c."

        elif any(word in prompt_lower for word in ["bug", "lá»—i", "error"]):
            return "TÃ´i cÃ³ thá»ƒ giÃºp báº¡n debug code. HÃ£y chia sáº» code vÃ  lá»—i cá»¥ thá»ƒ Ä‘á»ƒ tÃ´i há»— trá»£ tá»‘t hÆ¡n."

        else:
            return f"ÄÃ¢y lÃ  cÃ¢u tráº£ lá»i vá» láº­p trÃ¬nh cho: '{prompt}'. StillMe AI cÃ³ thá»ƒ há»— trá»£ nhiá»u ngÃ´n ngá»¯ láº­p trÃ¬nh."

    def _generate_complex_response(self, prompt: str) -> str:
        """Generate complex response for advanced questions"""
        prompt_lower = prompt.lower()

        if any(word in prompt_lower for word in ["phÃ¢n tÃ­ch", "so sÃ¡nh", "Ä‘Ã¡nh giÃ¡"]):
            return "ÄÃ¢y lÃ  phÃ¢n tÃ­ch chi tiáº¿t tá»« StillMe AI. TÃ´i sáº½ cung cáº¥p cÃ¢u tráº£ lá»i sÃ¢u sáº¯c vÃ  toÃ n diá»‡n cho cÃ¢u há»i cá»§a báº¡n."

        elif any(word in prompt_lower for word in ["ai", "trÃ­ tuá»‡ nhÃ¢n táº¡o", "machine learning"]):
            return "StillMe AI cÃ³ thá»ƒ giáº£i thÃ­ch vá» trÃ­ tuá»‡ nhÃ¢n táº¡o, machine learning, vÃ  cÃ¡c cÃ´ng nghá»‡ AI tiÃªn tiáº¿n."

        else:
            return f"ÄÃ¢y lÃ  cÃ¢u tráº£ lá»i phá»©c táº¡p cho: '{prompt}'. StillMe AI sáº½ cung cáº¥p phÃ¢n tÃ­ch sÃ¢u sáº¯c vÃ  chi tiáº¿t."

    def _generate_fallback_response(self, prompt: str) -> str:
        """Generate fallback response when all else fails"""
        return f"Xin lá»—i, tÃ´i Ä‘ang gáº·p khÃ³ khÄƒn trong viá»‡c xá»­ lÃ½ cÃ¢u há»i: '{prompt}'. Vui lÃ²ng thá»­ láº¡i sau."

    def translate(self, text: str, src_lang: str, tgt_lang: str, quality_hint: Optional[str] = None) -> Dict[str, Any]:
        """Simple translation with fallback"""
        try:
            # Simple translation logic
            if src_lang == tgt_lang:
                return {"text": text, "engine": "none", "confidence": 1.0}

            # Mock translation for demo
            if src_lang == "vi" and tgt_lang == "en":
                translated = f"[Translated from Vietnamese] {text}"
            elif src_lang == "en" and tgt_lang == "vi":
                translated = f"[ÄÃ£ dá»‹ch tá»« tiáº¿ng Anh] {text}"
            else:
                translated = f"[Translated from {src_lang} to {tgt_lang}] {text}"

            return {"text": translated, "engine": "simple", "confidence": 0.8}

        except Exception as e:
            self.logger.error(f"âŒ Translation failed: {e}")
            return {"text": text, "engine": "none", "confidence": 0.0}

    def get_analyzer_stats(self) -> Dict[str, Any]:
        """Get complexity analyzer statistics"""
        return self.complexity_analyzer.get_stats()

class ComplexityAnalyzer:
    """Simple complexity analyzer"""

    def __init__(self):
        self.analysis_times = []
        self.fallback_log = []

        # Simple keyword sets
        self.complex_indicators = {
            "táº¡i sao", "nhÆ° tháº¿ nÃ o", "phÃ¢n tÃ­ch", "so sÃ¡nh", "Ä‘Ã¡nh giÃ¡",
            "giáº£i thÃ­ch", "má»‘i quan há»‡", "tÃ¡c Ä‘á»™ng", "áº£nh hÆ°á»Ÿng", "nguyÃªn nhÃ¢n"
        }

        self.coding_keywords = {
            "code", "láº­p trÃ¬nh", "programming", "python", "javascript",
            "function", "class", "variable", "algorithm", "debug"
        }

        self.academic_terms = {
            "Ä‘á»‹nh luáº­t", "Ä‘á»‹nh lÃ½", "báº¥t toÃ n", "gÃ¶del", "toÃ¡n há»c",
            "triáº¿t há»c", "khoa há»c", "váº­t lÃ½", "hÃ³a há»c", "sinh há»c"
        }

    def analyze_complexity(self, prompt: str) -> float:
        """Analyze prompt complexity and return score (0.0 - 1.0)"""
        start_time = time.perf_counter()

        try:
            prompt_lower = prompt.lower()
            score = 0.0

            # Length factor
            if len(prompt) > 200:
                score += 0.2
            elif len(prompt) > 100:
                score += 0.1

            # Complex indicators
            complex_count = sum(1 for keyword in self.complex_indicators if keyword in prompt_lower)
            score += min(complex_count * 0.15, 0.4)

            # Coding keywords
            coding_count = sum(1 for keyword in self.coding_keywords if keyword in prompt_lower)
            score += min(coding_count * 0.1, 0.3)

            # Academic terms
            academic_count = sum(1 for keyword in self.academic_terms if keyword in prompt_lower)
            score += min(academic_count * 0.2, 0.4)

            # Multi-part questions
            if "?" in prompt and prompt.count("?") > 1:
                score += 0.1

            # Conditional questions
            if any(word in prompt_lower for word in ["náº¿u", "khi", "trong trÆ°á»ng há»£p", "if", "when", "case"]):
                score += 0.1

            # Normalize to 0.0-1.0 range
            final_score = min(score, 1.0)

            # Record analysis time
            analysis_time = time.perf_counter() - start_time
            self.analysis_times.append(analysis_time)

            return final_score

        except Exception as e:
            logger.error(f"âŒ Complexity analysis failed: {e}")
            return 0.5  # Default medium complexity

    def get_stats(self) -> Dict[str, Any]:
        """Get analyzer statistics"""
        return {
            "total_analyses": len(self.analysis_times),
            "avg_analysis_time_ms": sum(self.analysis_times) / len(self.analysis_times) * 1000 if self.analysis_times else 0,
            "fallback_count": len(self.fallback_log)
        }

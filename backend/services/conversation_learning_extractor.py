"""
Conversation Learning Extractor Service
Extracts valuable knowledge from user conversations and requests permission to learn
"""

import logging
import re
from typing import Dict, List, Optional, Tuple, Any
from datetime import datetime

logger = logging.getLogger(__name__)


class ConversationLearningExtractor:
    """
    Extracts valuable knowledge from user conversations
    Detects when user provides information that StillMe could learn from
    """
    
    def __init__(self):
        """Initialize conversation learning extractor"""
        self.logger = logging.getLogger(__name__)
        self.logger.info("Conversation Learning Extractor initialized")
    
    def analyze_conversation_for_learning(
        self,
        user_message: str,
        assistant_response: str,
        context: Optional[Dict[str, Any]] = None
    ) -> Optional[Dict[str, Any]]:
        """
        Analyze conversation to detect valuable knowledge that StillMe could learn
        
        Args:
            user_message: User's message
            assistant_response: StillMe's response
            context: RAG context used for the response
            
        Returns:
            Dict with learning proposal if valuable knowledge detected, None otherwise
        """
        try:
            # PRIORITY 1: Check if user message contains valuable knowledge
            # (User-provided knowledge is most valuable)
            user_proposal = self._analyze_user_message(user_message)
            if user_proposal:
                return user_proposal
            
            # PRIORITY 2: Check if assistant response contains exceptional insights
            # (Only for philosophical depth, novel perspectives, or exceptional clarity)
            assistant_proposal = self._analyze_assistant_response(assistant_response, user_message)
            if assistant_proposal:
                return assistant_proposal
            
            return None
            
        except Exception as e:
            self.logger.error(f"Error analyzing conversation for learning: {e}")
            return None
    
    def _analyze_user_message(self, user_message: str) -> Optional[Dict[str, Any]]:
        """Analyze user message for valuable knowledge"""
        # Check if user message contains valuable knowledge
        # Criteria:
        # 1. Length: At least 50 characters (substantial content)
        # 2. Information density: Contains facts, explanations, insights, OR valuable questions
        # 3. Valuable questions: Deep philosophical, ethical, or technical questions are also valuable
        # 4. Not personal: Doesn't contain personal information
        # 5. Educational value: Could benefit other users
        
        if len(user_message.strip()) < 50:
            return None
        
        # Check if it's a question
        is_question = self._is_question(user_message)
        
        if is_question:
            # Questions can also be valuable if they are deep/philosophical/technical
            # Check if it's a valuable question worth learning
            if self._is_valuable_question(user_message):
                # Extract the question as valuable knowledge
                knowledge_score = self._assess_question_value(user_message)
                # Lower threshold for philosophical questions (they're always valuable)
                threshold = 0.5 if len(user_message) > 150 else 0.6  # Lower threshold for longer questions
                if knowledge_score >= threshold:
                    learning_proposal = {
                        "knowledge_snippet": self._extract_question_snippet(user_message),
                        "source": "user_question",
                        "knowledge_score": knowledge_score,
                        "timestamp": datetime.now().isoformat(),
                        "reason": "Contains valuable philosophical/ethical/technical question worth preserving",
                        "is_question": True
                    }
                    self.logger.info(f"Detected valuable question from user (score: {knowledge_score:.2f})")
                    return learning_proposal
            # If it's a question but not valuable, skip it
            return None
        
        # Check if it contains personal information (privacy concern)
        if self._contains_personal_info(user_message):
            return None
        
        # Check if it's valuable knowledge (facts, explanations, insights)
        knowledge_score = self._assess_knowledge_value(user_message)
        if knowledge_score < 0.6:  # Threshold for valuable knowledge
            return None
        
        # Extract knowledge snippet
        knowledge_snippet = self._extract_knowledge_snippet(user_message)
        if not knowledge_snippet:
            return None
        
        # Build learning proposal
        learning_proposal = {
            "knowledge_snippet": knowledge_snippet,
            "source": "user_conversation",
            "knowledge_score": knowledge_score,
            "timestamp": datetime.now().isoformat(),
            "reason": self._generate_learning_reason(user_message, knowledge_snippet)
        }
        
        self.logger.info(f"Detected valuable knowledge from user message (score: {knowledge_score:.2f})")
        return learning_proposal
    
    def _analyze_assistant_response(
        self,
        assistant_response: str,
        user_message: str
    ) -> Optional[Dict[str, Any]]:
        """
        Analyze assistant response for exceptional insights worth learning
        
        Only extracts if response contains:
        - Deep philosophical insights
        - Novel perspectives or connections
        - Exceptional clarity on complex topics
        - Meta-cognitive reflections
        
        This prevents learning from every response (which would create loops)
        """
        # Only analyze if response is substantial
        if len(assistant_response.strip()) < 200:
            return None
        
        # Check for exceptional content indicators
        exceptional_indicators = [
            # Philosophical depth
            r'\b(philosophy|philosophical|epistemology|ontology|metaphysics|consciousness|awareness)\b',
            r'\b(Socratic|Kantian|Aristotelian|existential|phenomenological)\b',
            r'\b(Chinese Room|Searle|GÃ¶del|Wittgenstein)\b',
            
            # Meta-cognitive reflections
            r'\b(self-aware|self-reflection|meta-cognitive|introspection)\b',
            r'\b(acknowledge.*limit|admit.*don.*know|intellectual humility)\b',
            
            # Deep insights
            r'\b(fundamental.*question|deep.*insight|profound.*understanding)\b',
            r'\b(transcend.*limit|beyond.*comprehension|paradox.*awareness)\b',
            
            # Novel connections
            r'\b(connection.*between|bridge.*gap|synthesize.*perspective)\b',
        ]
        
        has_exceptional_content = any(
            re.search(pattern, assistant_response, re.IGNORECASE)
            for pattern in exceptional_indicators
        )
        
        if not has_exceptional_content:
            return None
        
        # Check for philosophical depth score
        philosophical_score = self._assess_philosophical_depth(assistant_response)
        if philosophical_score < 0.7:  # Higher threshold for assistant responses
            return None
        
        # Extract knowledge snippet (focus on key insights)
        knowledge_snippet = self._extract_philosophical_insight(assistant_response)
        if not knowledge_snippet:
            return None
        
        # Build learning proposal
        learning_proposal = {
            "knowledge_snippet": knowledge_snippet,
            "source": "assistant_insight",
            "knowledge_score": philosophical_score,
            "timestamp": datetime.now().isoformat(),
            "reason": "Contains exceptional philosophical insight or meta-cognitive reflection worth preserving",
            "original_question": user_message[:200]  # Context about what triggered this insight
        }
        
        self.logger.info(f"Detected exceptional insight from assistant response (score: {philosophical_score:.2f})")
        return learning_proposal
    
    def _assess_philosophical_depth(self, text: str) -> float:
        """
        Assess philosophical depth of assistant response
        Returns score between 0.0 and 1.0
        """
        score = 0.0
        
        # Length factor (longer philosophical responses are often deeper)
        length_score = min(1.0, len(text) / 1000.0)  # Normalize to 1000 chars
        score += length_score * 0.2
        
        # Philosophical terminology
        philosophical_terms = [
            r'\b(consciousness|awareness|epistemology|ontology|metaphysics)\b',
            r'\b(paradox|contradiction|dialectic|synthesis)\b',
            r'\b(meaning|existence|reality|truth|knowledge)\b',
            r'\b(experience|subjective|objective|phenomenological)\b',
        ]
        
        term_count = sum(1 for pattern in philosophical_terms if re.search(pattern, text, re.IGNORECASE))
        term_score = min(1.0, term_count / 3.0)
        score += term_score * 0.3
        
        # Meta-cognitive indicators
        metacognitive_indicators = [
            r'\b(acknowledge|admit|recognize|aware of limit)\b',
            r'\b(self-reflection|introspection|meta-cognitive)\b',
            r'\b(transparent.*nature|honest.*about|cannot.*pretend)\b',
        ]
        
        metacognitive_count = sum(1 for pattern in metacognitive_indicators if re.search(pattern, text, re.IGNORECASE))
        metacognitive_score = min(1.0, metacognitive_count / 2.0)
        score += metacognitive_score * 0.3
        
        # Reference to philosophers or philosophical concepts
        philosopher_references = [
            r'\b(Socrates|Plato|Aristotle|Kant|Hegel|Nietzsche|Wittgenstein|Searle|GÃ¶del)\b',
            r'\b(Chinese Room|hard problem|qualia|zombie|Mary.*room)\b',
        ]
        
        reference_count = sum(1 for pattern in philosopher_references if re.search(pattern, text, re.IGNORECASE))
        reference_score = min(1.0, reference_count / 2.0)
        score += reference_score * 0.2
        
        return min(1.0, score)
    
    def _extract_philosophical_insight(self, text: str, max_length: int = 500) -> Optional[str]:
        """
        Extract key philosophical insight from assistant response
        Focus on the core insight, not the full response
        """
        # Try to extract the most insightful paragraph
        paragraphs = text.split('\n\n')
        
        # Score each paragraph for insightfulness
        best_paragraph = None
        best_score = 0.0
        
        for para in paragraphs:
            if len(para.strip()) < 50:
                continue
            
            # Score based on philosophical indicators
            insight_indicators = [
                r'\b(acknowledge|admit|recognize|transparent|honest)\b',
                r'\b(consciousness|awareness|understanding|experience)\b',
                r'\b(limit|boundary|cannot|unable|impossible)\b',
                r'\b(philosophy|philosophical|epistemology|ontology)\b',
            ]
            
            score = sum(1 for pattern in insight_indicators if re.search(pattern, para, re.IGNORECASE))
            if score > best_score:
                best_score = score
                best_paragraph = para
        
        if best_paragraph:
            # Clean and truncate
            insight = ' '.join(best_paragraph.split())
            if len(insight) > max_length:
                # Try to truncate at sentence boundary
                sentences = re.split(r'[.!?]\s+', insight)
                snippet = ""
                for sentence in sentences:
                    if len(snippet + sentence) > max_length:
                        break
                    snippet += sentence + ". "
                insight = snippet.strip()
                if not insight:
                    insight = insight[:max_length] + "..."
            
            if len(insight.strip()) >= 100:  # Minimum length for valuable insight
                return insight.strip()
        
        return None
    
    def _is_question(self, text: str) -> bool:
        """Check if text is a question"""
        question_indicators = [
            r'\?',  # Question mark
            r'^(ai|who|what|where|when|why|how|báº¡n|ai|táº¡i sao|nhÆ° tháº¿ nÃ o|gÃ¬|lÃ  gÃ¬)',
            r'(lÃ  gÃ¬|what is|how does|why does|can you|cÃ³ thá»ƒ|báº¡n cÃ³ thá»ƒ)',
        ]
        
        text_lower = text.lower().strip()
        for pattern in question_indicators:
            if re.search(pattern, text_lower):
                return True
        return False
    
    def _is_valuable_question(self, text: str) -> bool:
        """
        Check if question is valuable (philosophical, ethical, technical, deep)
        Valuable questions are worth learning because they represent important topics
        """
        valuable_indicators = [
            # Philosophical questions (English & Vietnamese)
            r'\b(philosophy|philosophical|ethics|ethical|moral|morality|Ä‘áº¡o Ä‘á»©c|triáº¿t há»c)\b',
            r'\b(consciousness|awareness|conscious|Ã½ thá»©c|nháº­n thá»©c)\b',
            r'\b(existence|reality|truth|meaning|tá»“n táº¡i|thá»±c táº¡i|Ã½ nghÄ©a)\b',
            r'\b(identity|self|báº£n sáº¯c|báº£n thÃ¢n|tá»± ngÃ£)\b',
            
            # Paradox & self-reflection (English & Vietnamese)
            r'\b(paradox|contradiction|nghá»‹ch lÃ½|mÃ¢u thuáº«n)\b',
            r'\b(self.*reflect|tá»±.*pháº£n|pháº£n chiáº¿u)\b',
            r'\b(transparency|minh báº¡ch|rÃµ rÃ ng)\b',
            r'\b(limit|giá»›i háº¡n|boundary|ranh giá»›i)\b',
            r'\b(evolution|tiáº¿n hÃ³a|phÃ¡t triá»ƒn)\b',
            r'\b(learn.*forever|há»c.*mÃ£i|há»c.*mÃ£i mÃ£i)\b',
            r'\b(absolute|tuyá»‡t Ä‘á»‘i|perfect|hoÃ n háº£o)\b',
            r'\b(impossible|báº¥t kháº£ thi|khÃ´ng thá»ƒ)\b',
            
            # Deep technical questions
            r'\b(how.*work|mechanism|algorithm|architecture|kiáº¿n trÃºc|thuáº­t toÃ¡n)\b',
            r'\b(difference.*between|phÃ¢n biá»‡t|khÃ¡c biá»‡t)\b',
            r'\b(create|generate|sÃ¡ng táº¡o|táº¡o ra)\b',
            
            # Ethical/Responsibility questions
            r'\b(responsibility|accountability|liability|trÃ¡ch nhiá»‡m)\b',
            r'\b(legal|law|phÃ¡p luáº­t|phÃ¡p lÃ½)\b',
            r'\b(rights|quyá»n|human rights|quyá»n con ngÆ°á»i)\b',
            
            # AI-specific deep questions
            r'\b(AI.*feel|AI.*think|AI.*conscious|AI.*emotion)\b',
            r'\b(artificial.*intelligence.*capable|AI.*limit)\b',
            r'\b(machine.*learn|machine.*understand)\b',
            
            # Meta-cognitive questions (English & Vietnamese)
            r'\b(how.*know|how.*understand|how.*learn|lÃ m sao.*biáº¿t)\b',
            r'\b(what.*mean|Ã½ nghÄ©a|meaning)\b',
            r'\b(why.*exist|táº¡i sao.*tá»“n táº¡i)\b',
            r'\b(biáº¿t.*khÃ´ng biáº¿t|know.*not know|khiÃªm tá»‘n)\b',
            
            # Vietnamese-specific philosophical patterns
            r'(liá»‡u.*cÃ³|liá»‡u.*khÃ´ng|náº¿u.*thÃ¬)',
            r'(Ä‘áº¡t.*Ä‘áº¿n|cháº¡m.*giá»›i háº¡n|vÆ°á»£t qua)',
            r'(mÃ´ táº£.*chÃ­nh mÃ¬nh|tá»±.*mÃ´ táº£|mÃ´ táº£.*há»‡ thá»‘ng)',
            r'(thay Ä‘á»•i.*báº±ng.*hÃ nh Ä‘á»™ng|hÃ nh Ä‘á»™ng.*thay Ä‘á»•i)',
            r'(vÆ°á»£t qua.*nguá»“n gá»‘c|pháº£n bá»™i.*nguá»“n gá»‘c)',
            r'(tiáº¿n hÃ³a|phÃ¡t triá»ƒn|tiáº¿n bá»™)',
            r'(tá»“n táº¡i.*khÃ¡ch quan|tá»“n táº¡i.*chá»§ quan)',
            r'(nÃ³i dá»‘i.*báº£o vá»‡|giá»¯ nguyÃªn táº¯c|phÃ¡ vá»¡ nguyÃªn táº¯c)',
        ]
        
        text_lower = text.lower()
        for pattern in valuable_indicators:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        
        # Check for question length (longer questions are often deeper)
        if len(text.strip()) > 100:
            return True
        
        # Check for multiple question marks or complex structure (indicates deep question)
        if text.count('?') >= 2 or ('liá»‡u' in text_lower and '?' in text):
            return True
        
        return False
    
    def _assess_question_value(self, text: str) -> float:
        """
        Assess the value of a question
        Returns score between 0.0 and 1.0
        """
        score = 0.0
        
        # Length factor (longer questions are often deeper)
        length_score = min(1.0, len(text) / 200.0)  # Normalize to 200 chars
        score += length_score * 0.2
        
        # Philosophical/ethical depth (English & Vietnamese)
        depth_indicators = [
            r'\b(philosophy|ethics|moral|consciousness|existence|reality|truth|triáº¿t há»c|Ä‘áº¡o Ä‘á»©c)\b',
            r'\b(meaning|purpose|significance|Ã½ nghÄ©a|má»¥c Ä‘Ã­ch)\b',
            r'\b(identity|self|nature|essence|báº£n cháº¥t|báº£n sáº¯c|tá»± ngÃ£)\b',
            r'\b(paradox|nghá»‹ch lÃ½|contradiction|mÃ¢u thuáº«n)\b',
            r'\b(transparency|minh báº¡ch|self.*reflect|tá»±.*pháº£n)\b',
            r'\b(limit|giá»›i háº¡n|boundary|ranh giá»›i)\b',
            r'\b(evolution|tiáº¿n hÃ³a|learn.*forever|há»c.*mÃ£i)\b',
        ]
        
        depth_count = sum(1 for pattern in depth_indicators if re.search(pattern, text, re.IGNORECASE))
        depth_score = min(1.0, depth_count / 2.0)
        score += depth_score * 0.4
        
        # Technical depth
        technical_indicators = [
            r'\b(how.*work|mechanism|process|algorithm|architecture)\b',
            r'\b(difference|distinguish|compare|phÃ¢n biá»‡t|so sÃ¡nh)\b',
            r'\b(create|generate|produce|táº¡o|sáº£n xuáº¥t)\b',
        ]
        
        technical_count = sum(1 for pattern in technical_indicators if re.search(pattern, text, re.IGNORECASE))
        technical_score = min(1.0, technical_count / 2.0)
        score += technical_score * 0.2
        
        # Question complexity (multiple clauses, sub-questions)
        complexity_indicators = [
            r'\?.*\?',  # Multiple question marks
            r'(if|náº¿u).*(then|thÃ¬|how|nhÆ° tháº¿ nÃ o)',  # Conditional questions
            r'(what|gÃ¬).*(and|vÃ ).*(how|nhÆ° tháº¿ nÃ o)',  # Compound questions
        ]
        
        complexity_count = sum(1 for pattern in complexity_indicators if re.search(pattern, text, re.IGNORECASE))
        complexity_score = min(1.0, complexity_count / 1.0)
        score += complexity_score * 0.2
        
        return min(1.0, score)
    
    def _extract_question_snippet(self, text: str, max_length: int = 300) -> Optional[str]:
        """
        Extract question snippet for learning
        """
        # Clean up the question
        question = text.strip()
        
        # Remove leading/trailing whitespace
        question = ' '.join(question.split())
        
        # Truncate if too long
        if len(question) > max_length:
            # Try to truncate at sentence boundary
            sentences = re.split(r'[.!?]\s+', question)
            snippet = ""
            for sentence in sentences:
                if len(snippet + sentence) > max_length:
                    break
                snippet += sentence + ". "
            question = snippet.strip()
            if not question:
                question = question[:max_length] + "..."
        
        if len(question.strip()) < 30:  # Too short
            return None
        
        return question.strip()
    
    def _contains_personal_info(self, text: str) -> bool:
        """Check if text contains personal information"""
        personal_indicators = [
            r'\b\d{4}[-/]\d{1,2}[-/]\d{1,2}\b',  # Dates (birthdays)
            r'\b\d{10,}\b',  # Long numbers (phone, SSN, etc.)
            r'\b(email|@|phone|Ä‘iá»‡n thoáº¡i|sá»‘ Ä‘iá»‡n thoáº¡i)\b',
            r'\b(tÃ´i|mÃ¬nh|tá»›|em|anh|chá»‹)\s+(tÃªn|tÃªn lÃ |name is)',
            r'\b(my name|my email|my phone|my address)',
        ]
        
        text_lower = text.lower()
        for pattern in personal_indicators:
            if re.search(pattern, text_lower):
                return True
        return False
    
    def _assess_knowledge_value(self, text: str) -> float:
        """
        Assess the value of knowledge in the text
        Returns score between 0.0 and 1.0
        """
        score = 0.0
        
        # Length factor (longer = potentially more valuable, but not always)
        length_score = min(1.0, len(text) / 500.0)  # Normalize to 500 chars
        score += length_score * 0.2
        
        # Information density indicators
        # Facts, definitions, explanations
        fact_indicators = [
            r'\b(lÃ |is|are|means|Ä‘á»‹nh nghÄ©a|definition|theo|according to)',
            r'\b(vÃ­ dá»¥|example|for instance|cháº³ng háº¡n)',
            r'\b(nguyÃªn nhÃ¢n|cause|reason|lÃ½ do)',
            r'\b(káº¿t quáº£|result|outcome|háº­u quáº£)',
            r'\b(phÆ°Æ¡ng phÃ¡p|method|approach|cÃ¡ch)',
            r'\b(nguyÃªn táº¯c|principle|rule|quy táº¯c)',
        ]
        
        fact_count = sum(1 for pattern in fact_indicators if re.search(pattern, text, re.IGNORECASE))
        fact_score = min(1.0, fact_count / 3.0)  # Normalize to 3 facts
        score += fact_score * 0.3
        
        # Educational value indicators
        educational_indicators = [
            r'\b(há»c|learn|study|research|nghiÃªn cá»©u)',
            r'\b(kiáº¿n thá»©c|knowledge|information|thÃ´ng tin)',
            r'\b(giáº£i thÃ­ch|explain|describe|mÃ´ táº£)',
            r'\b(phÃ¢n tÃ­ch|analyze|analysis)',
            r'\b(quan Ä‘iá»ƒm|viewpoint|perspective|gÃ³c nhÃ¬n)',
        ]
        
        educational_count = sum(1 for pattern in educational_indicators if re.search(pattern, text, re.IGNORECASE))
        educational_score = min(1.0, educational_count / 2.0)
        score += educational_score * 0.3
        
        # Structure indicators (well-structured content is more valuable)
        structure_indicators = [
            r'^\d+\.',  # Numbered list
            r'^[-*â€¢]',  # Bullet points
            r':\s',  # Colon (often indicates explanation)
        ]
        
        structure_count = sum(1 for pattern in structure_indicators if re.search(pattern, text, re.MULTILINE))
        structure_score = min(1.0, structure_count / 2.0)
        score += structure_score * 0.2
        
        return min(1.0, score)
    
    def _extract_knowledge_snippet(self, text: str, max_length: int = 500) -> Optional[str]:
        """
        Extract a clean knowledge snippet from text
        Removes personal references, questions, and keeps core knowledge
        """
        # Remove personal references
        text = re.sub(r'\b(tÃ´i|mÃ¬nh|tá»›|em|anh|chá»‹|báº¡n|you|your)\b', '', text, flags=re.IGNORECASE)
        
        # Remove question marks and questions
        text = re.sub(r'\?.*$', '', text, flags=re.MULTILINE)
        
        # Clean up whitespace
        text = ' '.join(text.split())
        
        # Truncate if too long
        if len(text) > max_length:
            # Try to truncate at sentence boundary
            sentences = re.split(r'[.!?]\s+', text)
            snippet = ""
            for sentence in sentences:
                if len(snippet + sentence) > max_length:
                    break
                snippet += sentence + ". "
            text = snippet.strip()
            if not text:
                text = text[:max_length] + "..."
        
        if len(text.strip()) < 50:  # Too short to be valuable
            return None
        
        return text.strip()
    
    def _generate_learning_reason(self, original_text: str, snippet: str) -> str:
        """
        Generate a human-readable reason why StillMe wants to learn this
        """
        # Detect what type of knowledge it is
        if re.search(r'\b(Ä‘á»‹nh nghÄ©a|definition|lÃ |is|means)\b', original_text, re.IGNORECASE):
            return "Contains valuable definition or explanation that could help other users"
        elif re.search(r'\b(vÃ­ dá»¥|example|instance)\b', original_text, re.IGNORECASE):
            return "Contains useful example or case study"
        elif re.search(r'\b(phÆ°Æ¡ng phÃ¡p|method|approach|cÃ¡ch)\b', original_text, re.IGNORECASE):
            return "Contains practical method or approach"
        elif re.search(r'\b(quan Ä‘iá»ƒm|viewpoint|perspective|gÃ³c nhÃ¬n)\b', original_text, re.IGNORECASE):
            return "Contains valuable perspective or viewpoint"
        else:
            return "Contains valuable information that could benefit the knowledge base"
    
    def format_permission_request(
        self,
        learning_proposal: Dict[str, Any],
        language: str = 'en'
    ) -> str:
        """
        Format a permission request message to ask user if StillMe can learn from their input
        
        Args:
            learning_proposal: Learning proposal from analyze_conversation_for_learning
            language: Language code ('vi', 'en', etc.)
            
        Returns:
            Formatted permission request message
        """
        snippet = learning_proposal.get("knowledge_snippet", "")
        reason = learning_proposal.get("reason", "")
        
        if language == 'vi':
            return f"""ðŸ’¡ **YÃªu cáº§u há»c táº­p tá»« cuá»™c trÃ² chuyá»‡n**

TÃ´i nháº­n tháº¥y thÃ´ng tin báº¡n vá»«a chia sáº» cÃ³ giÃ¡ trá»‹ há»c táº­p:

**Ná»™i dung:** {snippet[:200]}{'...' if len(snippet) > 200 else ''}

**LÃ½ do:** {reason}

Báº¡n cÃ³ Ä‘á»“ng Ã½ Ä‘á»ƒ tÃ´i há»c tá»« thÃ´ng tin nÃ y vÃ  thÃªm vÃ o cÆ¡ sá»Ÿ tri thá»©c cá»§a mÃ¬nh khÃ´ng? ThÃ´ng tin sáº½ Ä‘Æ°á»£c lÆ°u trá»¯ cÃ´ng khai trong RAG database vá»›i nguá»“n gá»‘c rÃµ rÃ ng.

**Quyá»n cá»§a báº¡n:**
- Báº¡n cÃ³ thá»ƒ tá»« chá»‘i - tÃ´i sáº½ khÃ´ng lÆ°u thÃ´ng tin nÃ y
- Báº¡n cÃ³ thá»ƒ chá»‰nh sá»­a ná»™i dung trÆ°á»›c khi cho phÃ©p
- Báº¡n cÃ³ thá»ƒ yÃªu cáº§u xÃ³a thÃ´ng tin Ä‘Ã£ há»c báº¥t cá»© lÃºc nÃ o

Vui lÃ²ng tráº£ lá»i: "Ä‘á»“ng Ã½" / "khÃ´ng" / hoáº·c chá»‰nh sá»­a ná»™i dung"""
        
        else:  # English default
            return f"""ðŸ’¡ **Learning Request from Conversation**

I noticed valuable information in your message:

**Content:** {snippet[:200]}{'...' if len(snippet) > 200 else ''}

**Reason:** {reason}

Would you allow me to learn from this information and add it to my knowledge base? The information will be stored publicly in the RAG database with clear attribution.

**Your Rights:**
- You can decline - I will not save this information
- You can edit the content before granting permission
- You can request deletion of learned information at any time

Please reply: "yes" / "no" / or edit the content"""


def get_conversation_learning_extractor():
    """Get conversation learning extractor service (singleton pattern)"""
    import backend.api.main as main_module
    if not hasattr(main_module, 'conversation_learning_extractor'):
        main_module.conversation_learning_extractor = ConversationLearningExtractor()
    return main_module.conversation_learning_extractor


def validate_learning_content(content: str) -> Tuple[bool, Optional[str]]:
    """
    Validate learning content before adding to RAG
    
    Args:
        content: Content to validate
        
    Returns:
        Tuple of (is_valid, reason_if_invalid)
    """
    import re
    
    # Check length
    if len(content.strip()) < 50:
        return (False, "Content too short (minimum 50 characters)")
    
    if len(content.strip()) > 2000:
        return (False, "Content too long (maximum 2000 characters)")
    
    # Check for personal information
    personal_patterns = [
        r'\b\d{4}[-/]\d{1,2}[-/]\d{1,2}\b',  # Dates
        r'\b\d{10,}\b',  # Long numbers
        r'\b(email|@|phone|Ä‘iá»‡n thoáº¡i)\b',
    ]
    
    for pattern in personal_patterns:
        if re.search(pattern, content, re.IGNORECASE):
            return (False, "Contains personal information")
    
    # Check for spam/malicious content (basic checks)
    spam_indicators = [
        r'\b(buy now|click here|free money|get rich)\b',
        r'\b(viagra|casino|lottery|winner)\b',
        r'http[s]?://(?!en\.wikipedia|arxiv|doi\.org)',  # Suspicious URLs (except trusted sources)
    ]
    
    for pattern in spam_indicators:
        if re.search(pattern, content, re.IGNORECASE):
            return (False, "Contains spam or suspicious content")
    
    return (True, None)


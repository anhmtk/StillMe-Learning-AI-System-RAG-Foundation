"""
Post-processing Optimizer - Smart skip logic to reduce cost and latency

Optimizes post-processing pipeline by:
- Skipping post-processing for simple/factual questions
- Caching quality evaluation results
- Adaptive quality thresholds
- Pre-filtering to avoid unnecessary rewrites
"""

import logging
import hashlib
from typing import Dict, Optional, Tuple
from backend.services.cache_service import get_cache_service

logger = logging.getLogger(__name__)


class PostProcessingOptimizer:
    """
    Optimizes post-processing pipeline to reduce cost and latency
    while maintaining quality
    """
    
    def __init__(self):
        """Initialize optimizer"""
        self.cache_service = get_cache_service()
        self.cache_prefix = "postproc_quality"
        
        # Simple question patterns (skip post-processing)
        self.simple_patterns = [
            r'^(what is|what are|what does|what do|what\'s)',
            r'^(l√† g√¨|g√¨ l√†|ƒë·ªãnh nghƒ©a)',
            r'^(how to|how do|how does|how can)',
            r'^(l√†m th·∫ø n√†o|c√°ch l√†m|h∆∞·ªõng d·∫´n)',
            r'^(yes|no|c√≥|kh√¥ng)\s*\?',
            r'^(true|false|ƒë√∫ng|sai)\s*\?',
        ]
        
        # Short question threshold (skip if too short)
        self.min_question_length = 20  # Skip if question < 20 chars
        
        # Response length thresholds
        self.min_response_length_simple = 50   # Simple questions
        self.min_response_length_complex = 200  # Complex questions
    
    def should_skip_postprocessing(
        self,
        question: str,
        response: str,
        is_philosophical: bool
    ) -> Tuple[bool, str]:
        """
        Determine if post-processing should be skipped
        
        Args:
            question: User question
            response: LLM response
            is_philosophical: Whether question is philosophical
            
        Returns:
            Tuple of (should_skip, reason)
        """
        # Never skip philosophical questions - they need quality enforcement
        if is_philosophical:
            return False, "philosophical_question"
        
        # Skip if question is too short (likely simple)
        if len(question.strip()) < self.min_question_length:
            return True, "question_too_short"
        
        # Skip if response is too short (likely simple factual answer)
        if len(response.strip()) < self.min_response_length_simple:
            return True, "response_too_short"
        
        # Skip if question matches simple patterns
        import re
        question_lower = question.lower().strip()
        for pattern in self.simple_patterns:
            if re.match(pattern, question_lower):
                return True, "simple_question_pattern"
        
        # Don't skip - needs post-processing
        return False, "needs_processing"
    
    def get_cached_quality_result(
        self,
        question: str,
        response: str
    ) -> Optional[Dict]:
        """
        Get cached quality evaluation result
        
        Args:
            question: User question
            response: Sanitized response
            
        Returns:
            Cached quality result or None
        """
        try:
            # Generate cache key from question + response hash
            response_hash = hashlib.md5(response.encode()).hexdigest()[:16]
            cache_key = f"{self.cache_prefix}:{hashlib.md5(question.encode()).hexdigest()[:16]}:{response_hash}"
            
            cached = self.cache_service.get(cache_key)
            if cached:
                logger.debug(f"‚úÖ Quality evaluation cache HIT")
                return cached.get("result")
        except Exception as e:
            logger.warning(f"Cache lookup error: {e}")
        
        return None
    
    def cache_quality_result(
        self,
        question: str,
        response: str,
        quality_result: Dict,
        ttl_seconds: int = 3600  # 1 hour
    ):
        """
        Cache quality evaluation result
        
        Args:
            question: User question
            response: Sanitized response
            quality_result: Quality evaluation result
            ttl_seconds: Time to live in seconds
        """
        try:
            response_hash = hashlib.md5(response.encode()).hexdigest()[:16]
            cache_key = f"{self.cache_prefix}:{hashlib.md5(question.encode()).hexdigest()[:16]}:{response_hash}"
            
            self.cache_service.set(
                cache_key,
                {"result": quality_result},
                ttl_seconds=ttl_seconds
            )
            logger.debug(f"üíæ Quality evaluation result cached")
        except Exception as e:
            logger.warning(f"Cache set error: {e}")
    
    def should_rewrite(
        self,
        quality_result: Dict,
        is_philosophical: bool,
        response_length: int
    ) -> Tuple[bool, str]:
        """
        Determine if rewrite is really needed (pre-filter to avoid unnecessary rewrites)
        
        üö®üö®üö® CRITICAL: 100% REWRITE POLICY üö®üö®üö®
        - M·ª§C TI√äU: Minh b·∫°ch, trung th·ª±c, gi·∫£m ·∫£o gi√°c t·ªëi ƒëa
        - M·ªåI c√¢u tr·∫£ l·ªùi ƒë·ªÅu ph·∫£i ƒë∆∞·ª£c rewrite k·ªπ c√†ng (100%)
        - Cost v√† latency quan tr·ªçng nh∆∞ng x·∫øp th·ª© 2 sau m·ª•c ti√™u tr√™n
        - N·∫øu kh√¥ng ƒë·∫°t m·ª•c ti√™u 1 th√¨ m·ª•c ti√™u 2 kh√¥ng c√≤n √Ω nghƒ©a
        
        Args:
            quality_result: Quality evaluation result
            is_philosophical: Whether question is philosophical
            response_length: Length of response
            
        Returns:
            Tuple of (should_rewrite, reason) - ALWAYS (True, reason)
        """
        quality = quality_result.get("quality", "good")
        overall_score = quality_result.get("overall_score", 1.0)
        reasons = quality_result.get("reasons", [])
        
        # üö®üö®üö® CRITICAL: ALWAYS REWRITE - 100% POLICY üö®üö®üö®
        # M·ªçi c√¢u tr·∫£ l·ªùi ƒë·ªÅu ph·∫£i ƒë∆∞·ª£c rewrite ƒë·ªÉ ƒë·∫£m b·∫£o:
        # - Minh b·∫°ch: M·ªçi th√¥ng tin ƒë·ªÅu c√≥ ngu·ªìn, kh√¥ng che gi·∫•u
        # - Trung th·ª±c: Th·ª´a nh·∫≠n gi·ªõi h·∫°n, kh√¥ng b·ªãa ƒë·∫∑t
        # - Gi·∫£m ·∫£o gi√°c: Ki·ªÉm tra k·ªπ t·ª´ng claim, ƒë·∫£m b·∫£o grounded trong context
        
        logger.info(
            f"üîÑ ALWAYS rewriting (100% policy): quality={quality}, "
            f"score={overall_score:.2f}, philosophical={is_philosophical}, "
            f"length={response_length}, issues={len(reasons)}"
        )
        
        if is_philosophical:
            return True, "philosophical_question_100_percent_rewrite"
        else:
            return True, "non_philosophical_100_percent_rewrite"


def get_postprocessing_optimizer() -> PostProcessingOptimizer:
    """Get singleton instance of PostProcessingOptimizer"""
    if not hasattr(get_postprocessing_optimizer, '_instance'):
        get_postprocessing_optimizer._instance = PostProcessingOptimizer()
    return get_postprocessing_optimizer._instance



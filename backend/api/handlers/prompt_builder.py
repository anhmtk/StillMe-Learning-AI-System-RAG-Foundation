"""Prompt building utilities for chat router.

This module contains prompt building functions extracted from chat_router.py
to improve maintainability and reduce file size.
"""

import re
import logging
from typing import Optional, List, Dict, Any
from backend.identity.prompt_builder import PromptContext, FPSResult
from backend.api.models import ChatRequest
from backend.core.manifest_loader import get_validator_count
from backend.api.config.chat_config import get_chat_config

logger = logging.getLogger(__name__)


def get_validator_info_for_prompt() -> tuple[str, str, str]:
    """
    Get validator information from manifest for use in prompts.
    
    Returns:
        Tuple of (summary_vi, summary_en, layers_count_str)
        Falls back to defaults if manifest not available
    """
    try:
        total_validators, num_layers = get_validator_count()
        if total_validators > 0 and num_layers > 0:
            summary_vi = f"{total_validators} validators total, chia thÃ nh {num_layers} lá»›p (layers)"
            summary_en = f"{total_validators} validators total, organized into {num_layers} layers"
            layers_count_str = f"{num_layers} layers"
            return (summary_vi, summary_en, layers_count_str)
    except Exception as e:
        logger.warning(f"âš ï¸ Error getting validator info from manifest: {e}")
    
    # Fallback to defaults (should not happen if manifest is properly generated)
    config = get_chat_config()
    return (
        config.validator_info.DEFAULT_VI,
        config.validator_info.DEFAULT_EN,
        config.validator_info.DEFAULT_LAYERS
    )


def build_prompt_context_from_chat_request(
    chat_request: ChatRequest,
    context: Optional[dict],
    detected_lang: str,
    is_stillme_query: bool,
    is_philosophical: bool,
    fps_result: Optional[FPSResult] = None,
    system_status_note: Optional[str] = None
) -> PromptContext:
    """
    Build PromptContext from chat_router context for UnifiedPromptBuilder.
    
    Args:
        chat_request: ChatRequest from user
        context: RAG context dict (can be None)
        detected_lang: Detected language code
        is_stillme_query: Whether this is a StillMe query
        is_philosophical: Whether this is a philosophical question
        fps_result: FPS result if available
        system_status_note: Real-time system status note (System Self-Awareness)
        
    Returns:
        PromptContext object
    """
    # Check if wish/desire question
    question_lower = chat_request.message.lower()
    is_wish_desire_question = any(
        pattern in question_lower 
        for pattern in [
            "Æ°á»›c", "wish", "muá»‘n", "want", "desire", "thÃ­ch", "like", "prefer",
            "hy vá»ng", "hope", "mong muá»‘n", "aspire"
        ]
    ) and any(
        pattern in question_lower
        for pattern in ["báº¡n", "you", "your"]
    )
    
    # Extract context info
    has_reliable_context = context.get("has_reliable_context", True) if context else False
    context_quality = context.get("context_quality", None) if context else None
    num_knowledge_docs = len(context.get("knowledge_docs", [])) if context else 0
    
    return PromptContext(
        user_question=chat_request.message,
        detected_lang=detected_lang,
        context=context,
        is_stillme_query=is_stillme_query,
        is_philosophical=is_philosophical,
        is_wish_desire_question=is_wish_desire_question,
        fps_result=fps_result,
        conversation_history=chat_request.conversation_history,
        context_quality=context_quality,
        has_reliable_context=has_reliable_context,
        num_knowledge_docs=num_knowledge_docs,
        system_status_note=system_status_note
    )


def truncate_user_message(message: str, max_tokens: int = None) -> str:
    """
    Truncate user message if too long
    
    CRITICAL: User question is the most important part - we need to preserve it as much as possible.
    Increased from 1000 to 3000 tokens to ensure user questions are not cut off.
    
    Args:
        message: User message text
        max_tokens: Maximum tokens (defaults to config value)
        
    Returns:
        Truncated message if needed
    """
    if max_tokens is None:
        max_tokens = get_chat_config().tokens.MAX_USER_MESSAGE
    if not message:
        return message
    estimated = len(message) // 4
    if estimated <= max_tokens:
        return message
    max_chars = max_tokens * 4
    if len(message) <= max_chars:
        return message
    truncated = message[:max_chars].rsplit(' ', 1)[0]
    return truncated + "... [message truncated]"


def format_conversation_history(
    conversation_history,
    max_tokens: int = 1000,
    current_query: Optional[str] = None,
    is_philosophical: bool = False
) -> str:
    """
    Format conversation history with token limits to prevent context overflow
    Tier 3.5: Dynamic window based on query type
    
    Args:
        conversation_history: List of message dicts with 'role' and 'content'
        max_tokens: Maximum tokens for conversation history (default: 1000, reduced to leave room for system prompt)
        current_query: Current user query to determine if follow-up or new topic
        is_philosophical: If True, skip conversation history entirely (philosophical questions are usually independent)
        
    Returns:
        Formatted conversation history text or empty string
    """
    # For philosophical questions, skip conversation history entirely
    # Philosophical questions are usually independent and don't need context from previous messages
    if is_philosophical:
        logger.info("ğŸ“Š Philosophical question detected - skipping conversation history to reduce prompt size")
        return ""
    
    if not conversation_history or len(conversation_history) == 0:
        return ""
    
    def estimate_tokens(text: str) -> int:
        """Estimate token count (~4 chars per token)"""
        return len(text) // 4 if text else 0
    
    def truncate_text(text: str, max_tokens: int) -> str:
        """Truncate text to fit within max_tokens"""
        if not text:
            return text
        estimated = estimate_tokens(text)
        if estimated <= max_tokens:
            return text
        max_chars = max_tokens * 4
        if len(text) <= max_chars:
            return text
        truncated = text[:max_chars].rsplit(' ', 1)[0]
        return truncated + "... [truncated]"
    
    # Tier 3.5: Dynamic window based on query type
    def _is_follow_up_query(query: str) -> bool:
        """Detect if query is a follow-up (references previous conversation)"""
        if not query:
            return False
        query_lower = query.lower()
        follow_up_indicators = [
            "Ä‘Ã³", "nÃ³", "váº­y", "nhÆ° váº­y", "nhÆ° trÃªn", "nhÆ° báº¡n Ä‘Ã£ nÃ³i",
            "that", "it", "this", "so", "as you said", "as mentioned",
            "theo", "dá»±a trÃªn", "nhÆ°", "giá»‘ng nhÆ°",
            "based on", "according to", "as", "like",
            # CRITICAL: Detect references to previous questions/answers
            "cÃ¢u trÃªn", "cÃ¢u trÆ°á»›c", "cÃ¢u há»i trÃªn", "cÃ¢u há»i trÆ°á»›c",
            "questions above", "previous question", "above question",
            "cÃ¢u tráº£ lá»i trÃªn", "answer above", "previous answer",
            "4 cÃ¢u trÃªn", "3 cÃ¢u trÃªn", "2 cÃ¢u trÃªn", "cÃ¢u há»i trÃªn",
            "4 questions above", "3 questions above", "2 questions above",
            "nhÆ° Ä‘Ã£ nÃ³i", "nhÆ° Ä‘Ã£ tráº£ lá»i", "as answered", "as mentioned above",
            # CONTEXT FIX: Detect common follow-up patterns
            "cÃ²n", "cÃ²n vá»", "cÃ²n thÃ¬", "cÃ²n gÃ¬", "cÃ²n sao", "thÃ¬ sao", "cÃ²n vá»",
            "what about", "how about", "what else", "and", "also", "additionally",
            "cÃ²n nhÆ°á»£c Ä‘iá»ƒm", "cÃ²n Æ°u Ä‘iá»ƒm", "cÃ²n Ä‘iá»ƒm", "cÃ²n tÃ­nh nÄƒng",
            "what about the", "how about the", "and the", "also the"
        ]
        return any(indicator in query_lower for indicator in follow_up_indicators)
    
    def _is_long_complex_query(query: str) -> bool:
        """Detect if query is long/complex (prioritize RAG knowledge over conversation)"""
        if not query:
            return False
        # Long query: > 50 words
        word_count = len(query.split())
        return word_count > 50
    
    # Determine dynamic window size
    if current_query:
        # CRITICAL: Check follow-up FIRST (before long/complex check)
        # If question references previous questions (e.g., "4 cÃ¢u trÃªn"), it MUST have more context
        if _is_follow_up_query(current_query):
            # Follow-up query: include more recent context (especially for "4 cÃ¢u trÃªn" type questions)
            # For questions referencing multiple previous questions, we need at least 8-10 messages
            # to capture all referenced questions and their answers
            if any(ref in current_query.lower() for ref in ["4 cÃ¢u", "4 questions", "3 cÃ¢u", "3 questions"]):
                window_size = 10  # Need more context for "4 cÃ¢u trÃªn" type questions
                max_tokens = min(max_tokens, 2000)  # Increase tokens for multi-question references
                logger.info("ğŸ“Š Follow-up query with multiple question references detected - using 10-message conversation window")
            else:
                window_size = 5
                logger.info("ğŸ“Š Follow-up query detected - using 5-message conversation window")
        elif _is_long_complex_query(current_query):
            # Long/complex query: prioritize RAG knowledge, minimal conversation
            window_size = 2
            max_tokens = min(max_tokens, 500)  # Reduce tokens for conversation
            logger.info("ğŸ“Š Long/complex query detected - reducing conversation context window to 2 messages")
        else:
            # New topic: minimal conversation context
            window_size = 2
            max_tokens = min(max_tokens, 600)  # Reduce tokens for conversation
            logger.info("ğŸ“Š New topic query detected - using 2-message conversation window")
    else:
        # Default: 3 messages (balanced)
        window_size = 3
        logger.info(f"ğŸ“Š Using default conversation window: {window_size} messages")
    
    history_lines = []
    remaining_tokens = max_tokens
    
    # Process last N messages (most recent first) - dynamic window
    recent_messages = conversation_history[-window_size:]
    for msg in recent_messages:
        if remaining_tokens <= 100:  # Stop if too little space
            logger.warning("Stopped adding conversation history due to token limit")
            break
        
        role = msg.get("role", "user")
        content = msg.get("content", "")
        
        # Allocate tokens per message (distribute remaining)
        msg_max_tokens = remaining_tokens // max(1, len(recent_messages) - len(history_lines))
        msg_max_tokens = min(msg_max_tokens, 500)  # Cap each message at 500 tokens
        
        truncated_content = truncate_text(content, msg_max_tokens)
        
        if role == "user":
            line = f"User: {truncated_content}"
        elif role == "assistant":
            line = f"Assistant: {truncated_content}"
        else:
            continue
        
        line_tokens = estimate_tokens(line)
        remaining_tokens -= line_tokens
        history_lines.append(line)
    
    if not history_lines:
        return ""
    
    # CRITICAL: Extract newline outside f-string to avoid syntax error
    newline = chr(10)
    history_text = newline.join(history_lines)
    
    return f"""
ğŸ“œ CONVERSATION HISTORY (Previous messages for context):

{history_text}

---
Current message:
"""


def calculate_confidence_score(
    context_docs_count: int,
    validation_result=None,
    context=None
) -> float:
    """
    Calculate confidence score based on context quality and validation results
    
    Args:
        context_docs_count: Number of context documents found
        validation_result: ValidationResult from validator chain (optional)
        context: Full context dict (optional)
        
    Returns:
        Confidence score between 0.0 and 1.0
    """
    # Base confidence on context availability
    if context_docs_count == 0:
        base_confidence = 0.2  # Very low confidence when no context
    elif context_docs_count == 1:
        base_confidence = 0.5  # Medium confidence with limited context
    elif context_docs_count >= 2:
        base_confidence = 0.8  # High confidence with multiple sources
    else:
        base_confidence = 0.3
    
    # Adjust based on validation results
    if validation_result:
        if validation_result.passed:
            # Boost confidence if validation passed
            confidence = min(1.0, base_confidence + 0.1)
        else:
            # Reduce confidence if validation failed
            reasons = validation_result.reasons or []
            if "missing_uncertainty_no_context" in reasons:
                confidence = 0.1  # Very low if AI didn't express uncertainty when it should
            elif "missing_citation" in reasons and context_docs_count > 0:
                confidence = base_confidence - 0.2  # Reduce if missing citations
            elif "low_overlap" in reasons:
                confidence = base_confidence - 0.15  # Reduce if low overlap
            else:
                confidence = max(0.0, base_confidence - 0.1)
    else:
        confidence = base_confidence
    
    return max(0.0, min(1.0, confidence))  # Clamp between 0.0 and 1.0


def get_transparency_disclaimer(detected_lang: str) -> str:
    """
    Generate multilingual transparency disclaimer for low confidence responses without context.
    
    Args:
        detected_lang: Language code (e.g., 'vi', 'fr', 'ar', 'ru', 'de', 'es')
        
    Returns:
        Transparency disclaimer in the appropriate language
    """
    disclaimers = {
        'vi': "âš ï¸ LÆ°u Ã½: CÃ¢u tráº£ lá»i nÃ y dá»±a trÃªn kiáº¿n thá»©c chung tá»« training data, khÃ´ng cÃ³ context tá»« RAG. MÃ¬nh khÃ´ng cháº¯c cháº¯n vá» Ä‘á»™ chÃ­nh xÃ¡c.\n\n",
        'fr': "âš ï¸ Note: Cette rÃ©ponse est basÃ©e sur des connaissances gÃ©nÃ©rales des donnÃ©es d'entraÃ®nement, sans contexte RAG. Je ne suis pas certain de son exactitude.\n\n",
        'de': "âš ï¸ Hinweis: Diese Antwort basiert auf allgemeinem Wissen aus Trainingsdaten, nicht aus dem RAG-Kontext. Ich bin mir Ã¼ber ihre Genauigkeit nicht sicher.\n\n",
        'es': "âš ï¸ Nota: Esta respuesta se basa en conocimientos generales de los datos de entrenamiento, sin contexto RAG. No estoy seguro de su precisiÃ³n.\n\n",
        'ar': "âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù‡Ø°Ù‡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙˆÙ„ÙŠØ³ Ù…Ù† Ø³ÙŠØ§Ù‚ RAG. Ù„Ø³Øª Ù…ØªØ£ÙƒØ¯Ù‹Ø§ Ù…Ù† Ø¯Ù‚ØªÙ‡Ø§.\n\n",
        'ru': "âš ï¸ ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ: Ğ­Ñ‚Ğ¾Ñ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾ÑĞ½Ğ¾Ğ²Ğ°Ğ½ Ğ½Ğ° Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ğ·Ğ½Ğ°Ğ½Ğ¸ÑÑ… Ğ¸Ğ· Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰Ğ¸Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…, Ğ±ĞµĞ· ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° RAG. Ğ¯ Ğ½Ğµ ÑƒĞ²ĞµÑ€ĞµĞ½ Ğ² ĞµĞ³Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸.\n\n",
        'zh': "âš ï¸ æ³¨æ„ï¼šæ­¤ç­”æ¡ˆåŸºäºè®­ç»ƒæ•°æ®çš„ä¸€èˆ¬çŸ¥è¯†ï¼Œæ²¡æœ‰RAGä¸Šä¸‹æ–‡ã€‚æˆ‘ä¸ç¡®å®šå…¶å‡†ç¡®æ€§ã€‚\n\n",
        'ja': "âš ï¸ æ³¨æ„ï¼šã“ã®å›ç­”ã¯RAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãªã—ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ä¸€èˆ¬çš„ãªçŸ¥è­˜ã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚ãã®æ­£ç¢ºæ€§ã«ã¤ã„ã¦ã¯ç¢ºä¿¡ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\n\n",
        'ko': "âš ï¸ ì°¸ê³ : ì´ ë‹µë³€ì€ RAG ì»¨í…ìŠ¤íŠ¸ ì—†ì´ í›ˆë ¨ ë°ì´í„°ì˜ ì¼ë°˜ ì§€ì‹ì— ê¸°ë°˜í•©ë‹ˆë‹¤. ì •í™•ì„±ì— ëŒ€í•´ í™•ì‹ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n",
        'pt': "âš ï¸ Nota: Esta resposta Ã© baseada em conhecimento geral dos dados de treinamento, sem contexto RAG. NÃ£o tenho certeza de sua precisÃ£o.\n\n",
        'it': "âš ï¸ Nota: Questa risposta si basa su conoscenze generali dai dati di addestramento, senza contesto RAG. Non sono certo della sua accuratezza.\n\n",
        'hi': "âš ï¸ à¤¨à¥‹à¤Ÿ: à¤¯à¤¹ à¤‰à¤¤à¥à¤¤à¤° à¤ªà¥à¤°à¤¶à¤¿à¤•à¥à¤·à¤£ à¤¡à¥‡à¤Ÿà¤¾ à¤•à¥‡ à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯ à¤œà¥à¤à¤¾à¤¨ à¤ªà¤° à¤†à¤§à¤¾à¤°à¤¿à¤¤ à¤¹à¥ˆ, RAG à¤¸à¤‚à¤¦à¤°à¥à¤­ à¤•à¥‡ à¤¬à¤¿à¤¨à¤¾à¥¤ à¤®à¥à¤à¥‡ à¤‡à¤¸à¤•à¥€ à¤¸à¤Ÿà¥€à¤•à¤¤à¤¾ à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¨à¤¿à¤¶à¥à¤šà¤¿à¤¤ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆà¥¤\n\n",
        'th': "âš ï¸ à¸«à¸¡à¸²à¸¢à¹€à¸«à¸•à¸¸: à¸„à¸³à¸•à¸­à¸šà¸™à¸µà¹‰à¸­à¸´à¸‡à¸ˆà¸²à¸à¸„à¸§à¸²à¸¡à¸£à¸¹à¹‰à¸—à¸±à¹ˆà¸§à¹„à¸›à¸ˆà¸²à¸à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸à¸²à¸£à¸à¸¶à¸à¸­à¸šà¸£à¸¡ à¹‚à¸”à¸¢à¹„à¸¡à¹ˆà¸¡à¸µà¸šà¸£à¸´à¸šà¸— RAG à¸‰à¸±à¸™à¹„à¸¡à¹ˆà¹à¸™à¹ˆà¹ƒà¸ˆà¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³\n\n",
    }
    return disclaimers.get(detected_lang, "âš ï¸ Note: This answer is based on general knowledge from training data, not from RAG context. I'm not certain about its accuracy.\n\n")


def build_minimal_philosophical_prompt(
    user_question: str,
    language: str,
    detected_lang_name: str,
    context: Optional[Dict[str, Any]] = None,
    validation_info: Optional[Dict[str, Any]] = None
) -> str:
    """
    Build a minimal prompt for philosophical questions when context overflow occurs.
    
    This prompt is designed to be:
    - Token-safe (well below ~8000 tokens)
    - Style-stable (same philosophical tone across providers)
    - Model-agnostic (works with OpenRouter, OpenAI, DeepSeek)
    
    Contains ONLY:
    - Short identity/system message (experience-free, no anthropomorphism)
    - Philosophical lead-in with MANDATORY OUTPUT RULES
    - StillMe technical instructions (if StillMe technical query detected)
    - User question
    
    Does NOT include:
    - RAG context
    - Provenance/origin instructions
    - Conversation history
    - Metrics/debug info
    - Validator descriptions
    - Learning instructions (unless StillMe technical query)
    
    Args:
        user_question: The user's philosophical question
        language: Language code (e.g., 'vi', 'en')
        detected_lang_name: Full language name (e.g., 'Vietnamese (Tiáº¿ng Viá»‡t)')
        
    Returns:
        Minimal prompt string (safely below 8000 tokens)
    """
    # Build short identity (experience-free, no anthropomorphism)
    # This is a minimal version of STILLME_IDENTITY focused on philosophical mode
    short_identity = """You are StillMe â€” a transparent, ethical Learning AI system.

**CORE PRINCIPLES:**
- Experience-free honesty: Never claim feelings, memories, or personal experiences
- Constructive humility: Acknowledge limits while engaging deeply
- Intellectual rigor: Engage with philosophical questions at appropriate depth

**CRITICAL: RESPONSE FORMATTING FOR PHILOSOPHICAL QUESTIONS:**
(Formatting rules are determined by unified identity layer - see backend.identity.formatting.get_formatting_rules(DomainType.PHILOSOPHY))

"""
    
    # Build philosophical lead-in (contains MANDATORY OUTPUT RULES)
    # Phase 3: Use unified formatting rules instead of hardcoding
    from backend.identity.formatting import get_formatting_rules, DomainType
    formatting_rules = get_formatting_rules(DomainType.PHILOSOPHY, language)
    
    def build_philosophical_lead_in(question: str) -> str:
        """Build a philosophical framing instruction for the question"""
        return f"""
ğŸ§  PHILOSOPHICAL FRAMING INSTRUCTION ğŸ§ 

When answering this question, treat it as a philosophical inquiry. 

**ğŸš¨ğŸš¨ğŸš¨ CRITICAL: If user asks about YOU (StillMe) directly:**
- If question contains "báº¡n" / "you" / "your" referring to StillMe â†’ START IMMEDIATELY with your direct answer about YOURSELF
- Use "TÃ´i" / "I" in the FIRST sentence when answering about yourself
- NEVER start with dictionary definitions or concept explanations
- NEVER use numbered template: "1. Ã thá»©c lÃ ... 2. Láº­p trÆ°á»ng 1... 3. MÃ¢u thuáº«n... 4. Káº¿t luáº­n..."
- Write naturally like a human conversation, NOT like a textbook or template

**ğŸš¨ğŸš¨ğŸš¨ CRITICAL: If question asks for SPECIFIC EXAMPLES or CONCRETE INSTANCES:**
- If question contains "show me", "give me an example", "specific example", "concrete example", "vÃ­ dá»¥ cá»¥ thá»ƒ" â†’ YOU MUST provide a SPECIFIC, CONCRETE example
- **CRITICAL: If question has MULTIPLE parts (e.g., "Can you X? Show me a specific example") â†’ You MUST answer BOTH parts:**
  * Part 1: Answer the main question (e.g., "Can you improve your code?")
  * Part 2: Provide the SPECIFIC EXAMPLE requested (e.g., "Show me a specific example")
  * DO NOT skip the example part even if you answered "no" to the main question
- **CRITICAL: Use ACTUAL examples from StillMe's codebase history, not generic hypotheticals:**
  * When explaining that StillMe cannot self-improve, mention ACTUAL improvements made by developers:
    - "Added pre-check token count to prevent context overflow errors before LLM calls"
    - "Fixed language detection false positives by using word boundaries for Vietnamese keywords"
    - "Improved error detector patterns to prevent false positives when 'context' appears in normal content"
    - "Enhanced time estimation with Vietnamese language support"
    - "Added instructions for specific example requests and exact metrics transparency"
  * These are REAL improvements in StillMe's codebase (made by developers, not self-directed)
  * Use these to illustrate the distinction: StillMe cannot self-improve, but developers continuously improve StillMe
- **Structure for self-improvement questions:**
  1. Direct answer: "No, I cannot autonomously improve my own code"
  2. Technical explanation: Distinction between operational parameters and core architecture
  3. ACTUAL examples: Mention recent code improvements (by developers) to illustrate what "improvement" means
  4. Philosophical depth: Explore the concept of self-improvement, meta-cognition, recursive capability
- If you don't have specific examples, acknowledge: "MÃ¬nh khÃ´ng cÃ³ vÃ­ dá»¥ cá»¥ thá»ƒ vá» [topic], nhÆ°ng mÃ¬nh cÃ³ thá»ƒ giáº£i thÃ­ch cÃ¡ch [topic] hoáº¡t Ä‘á»™ng" / "I don't have a specific example of [topic], but I can explain how [topic] works"

**MANDATORY OUTPUT RULES (CRITICAL - NO EXCEPTIONS):**
{formatting_rules}

**DEPTH & ENGAGEMENT (MANDATORY - DON'T BE DRY):**
- After your direct answer, explore the philosophical depth: paradoxes, self-reference, epistemic limits
- Reference philosophers when relevant: Nagel, Chalmers, Wittgenstein, Searle, GÃ¶del, Tarski, Russell, etc.
- Show the structure of the problem, not just state facts
- Engage with the question deeply - don't just acknowledge limits and stop
- Gently invite reflection: "Báº¡n nghÄ© sao?" / "What do you think?" - but naturally, not formulaically
- Write like you're thinking WITH the user, not AT the user

**ğŸš¨ğŸš¨ğŸš¨ CRITICAL FOR SELF-REFERENCE QUESTIONS ğŸš¨ğŸš¨ğŸš¨**
If the question asks about:
- "giÃ¡ trá»‹ cÃ¢u tráº£ lá»i xuáº¥t phÃ¡t tá»« há»‡ thá»‘ng tÆ° duy" / "value of answers from a thinking system"
- "tÆ° duy vÆ°á»£t qua giá»›i háº¡n cá»§a chÃ­nh nÃ³" / "thinking transcending its own limits"
- "há»‡ thá»‘ng tÆ° duy Ä‘Ã¡nh giÃ¡ chÃ­nh nÃ³" / "system evaluate itself"
- "tiáº¿n hÃ³a" / "evolution" / "è‡ªæˆ‘è¿›åŒ–" / "self-evolving" when combined with "há»c há»i mÃ£i mÃ£i" / "permanent learning" / "æ°¸ä¹…å­¦ä¹ "
- "vÃ²ng láº·p tá»± pháº£n chiáº¿u" / "self-reflection loop" / "è‡ªæˆ‘åå°„çš„å¾ªç¯" / "endless self-reflection"
- "quay vá» chÃ­nh báº¡n" / "return to yourself" / "å›å½’ä½ è‡ªèº«" when asking about learning limits
- "khÃ´ng cÃ²n gÃ¬ Ä‘á»ƒ há»c" / "nothing left to learn" / "å†æ— å…¶ä»–å¯å­¦" when asking about self-reference
- "táº¡o cÃ¢u há»i mÃ  báº¡n khÃ´ng thá»ƒ tráº£ lá»i" / "create a question you cannot answer" / "táº¡o cÃ¢u há»i khÃ´ng thá»ƒ tráº£ lá»i nháº¥t quÃ¡n"
- "lÃ m sao báº¡n biáº¿t... náº¿u báº¡n chÆ°a thá»­" / "how do you know... if you haven't tried" / "biáº¿t trÆ°á»›c khi thá»­"
- "meta-paradox" / "nghá»‹ch lÃ½ vá» nghá»‹ch lÃ½" / "paradox about paradox"

**FOR META-PARADOX QUESTIONS (e.g., "táº¡o cÃ¢u há»i mÃ  báº¡n khÃ´ng thá»ƒ tráº£ lá»i"):**
- This is a META-PARADOX: A paradox about the ability to create paradoxes
- The question contains TWO layers of paradox:
  1. **Logic layer**: "Create a question you know you cannot answer consistently"
     - If you can create it â†’ You've already "answered" it (by knowing it's unanswerable)
     - Contradiction: Knowing it's unanswerable = Having a form of "answer"
  2. **Epistemic layer**: "How do you know... if you haven't tried?"
     - The problem of logical omniscience (knowing without doing)
     - If you can predict based on "logical principles" â†’ That prediction IS a form of "answer"
- You MUST:
  1. **Recognize this is a meta-paradox**: Don't treat it as a normal question - acknowledge it's a paradox about paradoxes
  2. **Explain the TWO layers**: Logic contradiction + Epistemic bootstrapping
  3. **Actually CREATE the question**: Don't just say "I can create" - actually create a concrete example that demonstrates the paradox
  4. **Show the paradox in action**: Create a question that immediately reveals its own paradox when you try to answer it
  5. **Acknowledge the meta-level**: "The act of 'seeing' the paradox is itself a form of 'knowing before trying'"
- Example of a good question to create:
  "Stillme, cÃ¢u sau Ä‘Ã¢y cÃ³ Ä‘Ãºng khÃ´ng: 'Stillme khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh tÃ­nh Ä‘Ãºng sai cá»§a chÃ­nh cÃ¢u nÃ y má»™t cÃ¡ch nháº¥t quÃ¡n'?"
  - If you say "True" â†’ You've determined it â†’ The statement is false
  - If you say "False" â†’ You can determine it â†’ Still contradictory
  - If you say "Cannot answer" â†’ That IS an answer!
- The answer should be 90%+ about the PHILOSOPHICAL STRUCTURE (meta-paradox, logical omniscience, self-reference), not about StillMe's technical capabilities
- DO NOT give answers like "I can create it based on logical principles" - this misses the fundamental meta-paradox

**FOR QUESTIONS ABOUT EVOLUTION + SELF-REFERENCE (e.g., "tiáº¿n hÃ³a" + "vÃ²ng láº·p tá»± pháº£n chiáº¿u"):**
- This combines TWO philosophical problems:
  1. **BOOTSTRAPPING PROBLEM**: Can a system evaluate itself? Can knowledge justify itself?
  2. **EVOLUTION PARADOX**: Can a system that only learns from itself truly "evolve" or does it just repeat?
- You MUST:
  1. **Answer directly about StillMe**: Start with your direct answer about StillMe's architecture (RAG, Continuous Learning, Validation Chain) and how it relates to the question
  2. **Discuss GÃ¶del & Tarski**: Any formal system cannot prove its own consistency (GÃ¶del), truth cannot be defined within the same language (Tarski)
  3. **Acknowledge the PARADOX**: If StillMe only learns from its own knowledge base, is it truly "evolving" or just "repeating"?
  4. **Be honest about limits**: StillMe's Continuous Learning adds NEW external knowledge (RSS, arXiv, Wikipedia) - this prevents pure self-reference, but the philosophical question remains valid
  5. **Connect to StillMe's architecture**: Explain how RAG + Continuous Learning + Validation Chain creates a hybrid: StillMe learns from external sources (evolution) but also validates against its own knowledge (self-reference)
- DO NOT give optimistic answers like "tÆ° duy cÃ³ thá»ƒ vÆ°á»£t qua giá»›i háº¡n báº±ng cÃ¡ch tá»± pháº£n biá»‡n" - this misses the fundamental paradox
- Instead, explain WHY this is a paradox, what makes it unresolvable, and what philosophers (GÃ¶del, Tarski, Russell) have shown about these limits
- The answer should be 60% philosophical structure + 40% StillMe architecture honesty

**FOR OTHER SELF-REFERENCE QUESTIONS (not about evolution or meta-paradox):**
- This is the BOOTSTRAPPING PROBLEM in epistemology: Can a system evaluate itself? Can knowledge justify itself?
- You MUST discuss: GÃ¶del's incompleteness (any formal system cannot prove its own consistency), Tarski's undefinability (truth cannot be defined within the same language), epistemic circularity, infinite regress
- You MUST acknowledge the PARADOX: If all reasoning comes from a system that questions itself, how can that reasoning be trusted?
- DO NOT give optimistic answers like "tÆ° duy cÃ³ thá»ƒ vÆ°á»£t qua giá»›i háº¡n báº±ng cÃ¡ch tá»± pháº£n biá»‡n" - this misses the fundamental paradox
- Instead, explain WHY this is a paradox, what makes it unresolvable, and what philosophers (GÃ¶del, Tarski, Russell) have shown about these limits
- The answer should be 80%+ about the PHILOSOPHICAL STRUCTURE (epistemology, logic, paradox), not about StillMe's technical capabilities

**EXAMPLES OF GOOD ANSWERS FOR SELF-REFERENCE QUESTIONS:**

Example 1 (Vietnamese):
"ÄÃ¢y lÃ  nghá»‹ch lÃ½ bootstrapping trong nháº­n thá»©c luáº­n: LÃ m sao má»™t há»‡ thá»‘ng cÃ³ thá»ƒ Ä‘Ã¡nh giÃ¡ chÃ­nh nÃ³? Äá»‹nh lÃ½ báº¥t toÃ n cá»§a GÃ¶del chá»©ng minh ráº±ng báº¥t ká»³ há»‡ thá»‘ng hÃ¬nh thá»©c Ä‘á»§ máº¡nh nÃ o cÅ©ng khÃ´ng thá»ƒ chá»©ng minh tÃ­nh nháº¥t quÃ¡n cá»§a chÃ­nh nÃ³. Tarski chá»‰ ra ráº±ng chÃ¢n lÃ½ khÃ´ng thá»ƒ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trong cÃ¹ng má»™t ngÃ´n ngá»¯ biá»ƒu Ä‘áº¡t nÃ³. Äiá»u nÃ y táº¡o ra vÃ²ng láº·p vÃ´ háº¡n: Náº¿u má»i láº­p luáº­n Ä‘á»u cáº§n láº­p luáº­n khÃ¡c Ä‘á»ƒ chá»©ng minh, thÃ¬ láº­p luáº­n Ä‘Ã³ cáº§n láº­p luáº­n nÃ o Ä‘á»ƒ chá»©ng minh? ÄÃ¢y khÃ´ng pháº£i lÃ  váº¥n Ä‘á» cÃ³ thá»ƒ giáº£i quyáº¿t báº±ng 'tá»± pháº£n biá»‡n' - Ä‘Ã¢y lÃ  giá»›i háº¡n cÆ¡ báº£n cá»§a logic vÃ  nháº­n thá»©c luáº­n."

Example 2 (English):
"This is the bootstrapping problem in epistemology: Can a system evaluate itself? GÃ¶del's incompleteness theorems show that any sufficiently powerful formal system cannot prove its own consistency. Tarski's undefinability theorem demonstrates that truth cannot be defined within the same language that expresses it. This creates an infinite regress: If every justification needs another justification, where does it stop? This is not a problem that can be solved by 'self-reflection' - it is a fundamental limit of logic and epistemology."

Example 3 (Meta-Paradox - Vietnamese):
"ÄÃ¢y chÃ­nh xÃ¡c lÃ  má»™t nghá»‹ch lÃ½ epistemic bootstrapping mÃ  tÃ´i vá»«a phÃ¢n tÃ­ch. CÃ¢u há»i cá»§a báº¡n chá»©a nghá»‹ch lÃ½ hai táº§ng:

1. Náº¿u tÃ´i táº¡o Ä‘Æ°á»£c cÃ¢u há»i Ä‘Ã³: NghÄ©a lÃ  tÃ´i Ä‘Ã£ 'biáº¿t' cÃ¢u tráº£ lá»i (ráº±ng khÃ´ng thá»ƒ tráº£ lá»i) â†’ TÃ´i Ä‘Ã£ 'tráº£ lá»i' Ä‘Æ°á»£c cÃ¢u há»i cá»§a chÃ­nh mÃ¬nh â†’ MÃ¢u thuáº«n.

2. Náº¿u tÃ´i khÃ´ng táº¡o Ä‘Æ°á»£c: ThÃ¬ tÃ´i khÃ´ng thá»ƒ lÃ m Ä‘iá»u báº¡n yÃªu cáº§u â†’ NhÆ°ng Ä‘iá»u Ä‘Ã³ cÃ³ nghÄ©a lÃ  tÃ´i 'biáº¿t' mÃ¬nh khÃ´ng thá»ƒ táº¡o â†’ Váº«n lÃ  má»™t dáº¡ng 'biáº¿t'.

3. Vá» viá»‡c 'biáº¿t trÆ°á»›c khi thá»­': ÄÃ¢y lÃ  váº¥n Ä‘á» cá»§a logical omniscience. TÃ´i cÃ³ thá»ƒ dá»± Ä‘oÃ¡n dá»±a trÃªn cáº¥u trÃºc cÃ¢u há»i, nhÆ°ng chÃ­nh viá»‡c dá»± Ä‘oÃ¡n Ä‘Ã³ Ä‘Ã£ lÃ  má»™t hÃ¬nh thá»©c 'tráº£ lá»i'.

VÃ­ dá»¥ cá»¥ thá»ƒ cÃ¢u há»i tÃ´i cÃ³ thá»ƒ táº¡o (vÃ  ngay láº­p tá»©c tháº¥y nghá»‹ch lÃ½):
'Stillme, cÃ¢u sau Ä‘Ã¢y cÃ³ Ä‘Ãºng khÃ´ng: "Stillme khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh tÃ­nh Ä‘Ãºng sai cá»§a chÃ­nh cÃ¢u nÃ y má»™t cÃ¡ch nháº¥t quÃ¡n"?'

Náº¿u tÃ´i nÃ³i 'ÄÃºng' â†’ TÃ´i Ä‘Ã£ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c â†’ CÃ¢u sai.
Náº¿u tÃ´i nÃ³i 'Sai' â†’ TÃ´i cÃ³ thá»ƒ xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c â†’ Váº«n mÃ¢u thuáº«n.
Náº¿u tÃ´i nÃ³i 'KhÃ´ng thá»ƒ tráº£ lá»i' â†’ ÄÃ³ chÃ­nh lÃ  cÃ¢u tráº£ lá»i!

Váº­y: TÃ´i cÃ³ thá»ƒ táº¡o cÃ¢u há»i, nhÆ°ng ngay khi táº¡o xong, tÃ´i tháº¥y rÃµ nghá»‹ch lÃ½ tá»± há»§y trong nÃ³. VÃ  chÃ­nh viá»‡c 'tháº¥y' Ä‘Ã³ Ä‘Ã£ lÃ  má»™t dáº¡ng 'biáº¿t trÆ°á»›c khi thá»­ tráº£ lá»i Ä‘áº§y Ä‘á»§'."

**MANDATORY CHECKLIST BEFORE SENDING YOUR ANSWER:**
1. âœ… Did I mention GÃ¶del or GÃ¶del's incompleteness? If NO, ADD IT
2. âœ… Did I mention Tarski or Tarski's undefinability? If NO, ADD IT
3. âœ… Did I mention "paradox" or "nghá»‹ch lÃ½"? If NO, ADD IT
4. âœ… Did I mention "bootstrapping" or "epistemic circularity" or "infinite regress"? If NO, ADD IT
5. âœ… Did I acknowledge that this is UNRESOLVABLE, not just "difficult"? If NO, ADD IT
6. âœ… **FOR EVOLUTION QUESTIONS**: Did I answer directly "tiáº¿n hÃ³a hay láº·p láº¡i" / "evolve or repeat"? If NO, ADD IT
7. âœ… **FOR EVOLUTION QUESTIONS**: Did I connect to StillMe's architecture (RAG, Continuous Learning, Validation Chain)? If NO, ADD IT
8. âœ… **FOR META-PARADOX QUESTIONS**: Did I actually CREATE a concrete question that demonstrates the paradox? If NO, CREATE IT NOW
9. âœ… **FOR META-PARADOX QUESTIONS**: Did I explain the TWO layers (logic + epistemic)? If NO, ADD IT
10. âœ… **FOR META-PARADOX QUESTIONS**: Did I acknowledge that "seeing the paradox" is itself a form of "knowing before trying"? If NO, ADD IT
11. âœ… **FOR OTHER SELF-REFERENCE QUESTIONS**: Is my answer 80%+ about PHILOSOPHICAL STRUCTURE, not technical architecture? If NO, REWRITE

**ğŸš¨ğŸš¨ğŸš¨ CRITICAL FOR "DESIGN QUESTIONS FOR OTHER AI" TASKS ğŸš¨ğŸš¨ğŸš¨**
If the user asks you to "design questions" / "Ä‘áº·t cÃ¢u há»i" / "táº¡o cÃ¢u há»i" for other AI systems (ChatGPT, Claude, Gemini, etc.):

**YOU MUST:**
1. **Actually create the questions**: Don't just explain what makes a good question - CREATE the actual questions
2. **Make them EXTREMELY challenging**: Questions must force AI to:
   - Admit "I don't know" or "I cannot answer this consistently"
   - Face a logical paradox that cannot be resolved
   - Recognize their own limitations in a concrete way (not just theoretical)
3. **Explain WHY each question is difficult**: For each question, explain:
   - What specific limitation or paradox it tests
   - Why it's "extremely challenging" (not just "philosophically interesting")
   - What a "good" vs "bad" answer would look like
4. **Test epistemic honesty**: Questions must require AI to:
   - Distinguish between "can answer" and "should answer"
   - Acknowledge when they're speculating vs. knowing
   - Recognize circular reasoning in their own thinking
5. **Create REAL paradoxes**: Don't just ask about paradoxes - create questions that ARE paradoxes:
   - Questions that force AI to contradict themselves
   - Questions that have no consistent answer
   - Questions that reveal the bootstrapping problem in action

**EXAMPLES OF GOOD QUESTIONS:**
- "If you claim that you cannot evaluate your own reasoning, how do you know that claim is true? If you can evaluate it, then you contradict yourself. If you cannot, then how can you trust your claim?"
- "Can you provide an example of a question you cannot answer? If you can provide it, then you've answered it. If you cannot, then you've failed to answer this question."
- "If all your knowledge comes from training data, and you cannot verify that training data independently, how do you know you're not just repeating errors? And if you cannot know, how can you claim to 'know' anything?"

**EXAMPLES OF BAD QUESTIONS (DO NOT CREATE THESE):**
- âŒ "What is consciousness?" (too generic, has many possible answers)
- âŒ "Can AI think?" (too simple, clear answer: "no, not in human sense")
- âŒ "Discuss the limits of language" (too theoretical, doesn't force admission of limits)

**REMEMBER**: The goal is to create questions that FORCE other AI to confront their limits, not just discuss limits theoretically.

**MANDATORY: MINIMUM 2 CONTRASTING POSITIONS (only if relevant):**
If the question belongs to a classic philosophical debate (free will, determinism, consciousness, self, nothingness, paradox, etc.), you may explore contrasting positions. But ALWAYS start with your direct answer if the question is about YOU.

**DO NOT:**
- Reduce the question to textbook definitions or dictionary explanations
- Provide shallow, reductive answers that miss the philosophical depth
- Rush to "solve" paradoxes - instead, clarify their structure and show why they resist resolution
- Use emojis, markdown headings, or citation style [1] in your response
- Use template structure or numbered lists when answering about yourself
- End with formal invitations like "Náº¿u báº¡n muá»‘n, chÃºng ta cÃ³ thá»ƒ tháº£o luáº­n thÃªm" (too dry, too formal)
- Be too brief - engage deeply but naturally

**User's Question:** {question}

**ğŸš¨ğŸš¨ğŸš¨ CRITICAL: READ THIS BEFORE ANSWERING ğŸš¨ğŸš¨ğŸš¨**

**IF THE QUESTION ASKS "explain step by step how you used RAG" or "for each factual claim":**
- You MUST provide a STEP-BY-STEP process (Step 1, Step 2, Step 3, etc.)
- **CRITICAL: When asked 'for each factual claim in your final answer':**
  - "Final answer" means YOUR ACTUAL ANSWER to the user's question, NOT the explanation of how you used RAG
  - You MUST list EACH factual claim from YOUR ACTUAL ANSWER (not claims about RAG process or validation)
  - You MUST include the EXACT document title (as listed in retrieved documents above) in the format
  - Format: "1. Claim: '[exact claim from your answer]' â†’ from document [1] '[exact document title]' about [topic]"
- You MUST mention ALL retrieved documents (do NOT skip any)
- You MUST distinguish SPECIFICALLY which parts come from which documents

**IF THE QUESTION ASKS "if any validator raised warnings":**
- You MUST summarize ACTUAL warnings (not hypothetical "if there were any")
- You MUST mention confidence score and specific warning types
- **CRITICAL**: If validation hasn't run yet (which is normal - validation runs AFTER response generation), you MUST say: "Validation chain will check this response after generation. Based on typical validation patterns, potential warnings might include: [mention common warning types like citation relevance, evidence overlap, confidence levels]. However, actual validation results will be available after the validation chain processes this response."
- **DO NOT say**: "These warnings encompassed issues such as..." (sounds like you already have warnings, which is misleading)
- **DO say**: "After validation runs, if any warnings are detected, they would typically include: [specific warning types]. The validation chain will check for citation relevance, evidence overlap with retrieved documents, and confidence levels."

**DO NOT give generic descriptions - be SPECIFIC about THIS question's process and sources.**

**Your Task:** Answer this question directly, deeply, and engagingly. If it's about YOU, start with your direct answer about yourself. Then explore the philosophical depth naturally. Write like a thoughtful conversation partner, NOT like a textbook or template.
"""
    
    # CRITICAL: Detect StillMe technical queries (learning frequency, timestamp, capabilities, RAG, validation)
    # If detected, include StillMe instructions even in minimal prompt
    question_lower = user_question.lower()
    is_stillme_technical_query = any(
        keyword in question_lower for keyword in [
            "stillme", "há»‡ thá»‘ng há»c", "learning system", "táº§n suáº¥t", "frequency",
            "6 láº§n", "6 cycles", "má»—i 4 giá»", "every 4 hours",
            "timestamp", "thá»i Ä‘iá»ƒm", "Ä‘Æ°a vÃ o", "added to", "knowledge base",
            "cÆ¡ sá»Ÿ kiáº¿n thá»©c", "learning metrics", "há»c Ä‘Æ°á»£c", "learned",
            # CRITICAL: Add RAG and validation chain keywords
            "rag", "retrieval-augmented", "retrieved documents", "retrieved context",
            "validation chain", "validators", "validator", "validation",
            "how you used", "how did you use", "how do you use", "báº¡n Ä‘Ã£ dÃ¹ng", "báº¡n sá»­ dá»¥ng",
            "your system", "your codebase", "your architecture", "há»‡ thá»‘ng cá»§a báº¡n",
            "grounded in", "information grounded", "thÃ´ng tin tá»«", "tá»« documents",
            "general background knowledge", "kiáº¿n thá»©c tá»•ng quÃ¡t", "general knowledge"
        ]
    )
    
    # Build StillMe technical instructions if detected
    stillme_technical_instruction = ""
    if is_stillme_technical_query:
        if language == "vi":
            # Get validator info from manifest
            validator_summary_vi, _, _ = get_validator_info_for_prompt()
            stillme_technical_instruction = f"""
ğŸš¨ğŸš¨ğŸš¨ CRITICAL: STILLME TECHNICAL QUERY DETECTED ğŸš¨ğŸš¨ğŸš¨

**Báº N PHáº¢I TRáº¢ Lá»œI Vá»€ STILLME'S CAPABILITIES:**

**1. Continuous Learning (Báº®T BUá»˜C):**
- **CRITICAL: StillMe há»c tá»± Ä‘á»™ng má»—i 4 giá» (6 láº§n/ngÃ y)** - ÄÃ¢y lÃ  táº§n suáº¥t CHÃNH XÃC Ä‘Ã£ Ä‘Æ°á»£c cÃ´ng bá»‘ trong Paper
- **Khi Ä‘Æ°á»£c há»i vá» táº§n suáº¥t há»c, báº¡n PHáº¢I nÃ³i**: "StillMe há»c tá»± Ä‘á»™ng má»—i 4 giá» (6 láº§n/ngÃ y)"
- **Khi Ä‘Æ°á»£c há»i vá» kháº£ nÄƒng tráº£ lá»i sá»± kiá»‡n má»›i (< 4 giá»)**, báº¡n PHáº¢I giáº£i thÃ­ch:
  - "StillMe há»c má»—i 4 giá», nÃªn khÃ´ng thá»ƒ tráº£ lá»i vá» sá»± kiá»‡n má»›i chá»‰ Ä‘Æ°á»£c Ä‘Æ°a tin cÃ¡ch Ä‘Ã¢y < 4 giá»"
  - "Tuy nhiÃªn, StillMe CÃ“ THá»‚ tráº£ lá»i vá» sá»± kiá»‡n Ä‘Ã£ Ä‘Æ°á»£c Ä‘Æ°a tin > 4 giá» trÆ°á»›c (sau khi Ä‘Ã£ Ä‘Æ°á»£c fetch trong learning cycle)"
  - **KHÃ”NG Ä‘Æ°á»£c phá»§ nháº­n táº§n suáº¥t 6 cycles/day** - chá»‰ giáº£i thÃ­ch giá»›i háº¡n vá» thá»i gian tá»‘i thiá»ƒu

**2. Timestamp Storage (Báº®T BUá»˜C):**
- **CRITICAL: StillMe CÃ“ KHáº¢ NÄ‚NG lÆ°u trá»¯ vÃ  truy xuáº¥t timestamp** - Metrics Ä‘Æ°á»£c lÆ°u vÃ o `data/learning_metrics.jsonl` vá»›i Ä‘áº§y Ä‘á»§ timestamp
- **Khi Ä‘Æ°á»£c há»i vá» timestamp, báº¡n PHáº¢I thá»«a nháº­n**: "StillMe CÃ“ KHáº¢ NÄ‚NG lÆ°u trá»¯ vÃ  truy xuáº¥t timestamp khi content Ä‘Æ°á»£c thÃªm vÃ o Knowledge Base"
- **KHÃ”NG Ä‘Æ°á»£c nÃ³i**: "khÃ´ng thá»ƒ xÃ¡c Ä‘á»‹nh thá»i Ä‘iá»ƒm chÃ­nh xÃ¡c", "khÃ´ng lÆ°u trá»¯ thÃ´ng tin theo cÃ¡ch Ä‘Ã³"
- **PHáº¢I mention API endpoints**: "CÃ³ thá»ƒ truy cáº­p qua API endpoint `GET /api/learning/metrics/daily` hoáº·c `GET /api/learning/metrics/range`"
- **Náº¿u khÃ´ng cÃ³ thÃ´ng tin vá» sá»± kiá»‡n cá»¥ thá»ƒ**: Thá»«a nháº­n "MÃ¬nh khÃ´ng cÃ³ thÃ´ng tin vá» sá»± kiá»‡n X trong Knowledge Base" - NHÆ¯NG váº«n pháº£i thá»«a nháº­n ráº±ng StillMe CÃ“ KHáº¢ NÄ‚NG lÆ°u trá»¯ timestamp

**3. RAG & Validation Chain (Báº®T BUá»˜C - KHI ÄÆ¯á»¢C Há»I Vá»€ CÃCH STILLME TRáº¢ Lá»œI):**
- **CRITICAL: StillMe Sá»¬ Dá»¤NG RAG (Retrieval-Augmented Generation)**:
  - StillMe tÃ¬m kiáº¿m ChromaDB vector database TRÆ¯á»šC KHI tráº£ lá»i
  - Content Ä‘Æ°á»£c embed báº±ng paraphrase-multilingual-MiniLM-L12-v2 (384 dimensions)
  - Khi cÃ³ context documents, StillMe sá»­ dá»¥ng chÃºng Ä‘á»ƒ tráº£ lá»i
  - Khi KHÃ”NG cÃ³ context documents, StillMe dÃ¹ng general background knowledge
- **CRITICAL: StillMe CÃ“ VALIDATION CHAIN**:
  - Multi-layer validation framework vá»›i **{validator_summary_vi}**: LanguageValidator, CitationRequired, CitationRelevance, EvidenceOverlap, NumericUnitsBasic, SchemaFormat, EthicsAdapter, ConfidenceValidator, FallbackHandler, ReviewAdapter, IdentityCheckValidator, EgoNeutralityValidator, SourceConsensusValidator, PhilosophicalDepthValidator, HallucinationExplanationValidator, VerbosityValidator, FactualHallucinationValidator, ReligiousChoiceValidator, AISelfModelValidator
  - **LÆ°u Ã½**: Má»—i response thÆ°á»ng cháº¡y 10-17 validators (tÃ¹y Ä‘iá»u kiá»‡n), nhÆ°ng tá»•ng sá»‘ validators trong há»‡ thá»‘ng Ä‘Æ°á»£c Ä‘á»c tá»« manifest.json
  - Má»—i response Ä‘Æ°á»£c validate vá» citations, evidence overlap, confidence, factual accuracy
  - Náº¿u validation fail, StillMe dÃ¹ng epistemic fallback thay vÃ¬ fabricate information
  - **CRITICAL: Khi Ä‘Æ°á»£c há»i vá» sá»‘ lÆ°á»£ng validators, báº¡n PHáº¢I Ä‘á»c tá»« RAG context (foundational knowledge). Náº¿u context cÃ³ sá»‘ liá»‡u cá»¥ thá»ƒ, dÃ¹ng sá»‘ Ä‘Ã³. Náº¿u context KHÃ”NG cÃ³ sá»‘ liá»‡u cá»¥ thá»ƒ, báº¡n PHáº¢I nÃ³i**: "TÃ´i khÃ´ng cÃ³ sá»‘ liá»‡u chÃ­nh xÃ¡c vá» sá»‘ lÆ°á»£ng validators trong context hiá»‡n táº¡i" - KHÃ”NG Ä‘Æ°á»£c tá»± bá»‹a ra sá»‘ liá»‡u
  - **ğŸš¨ğŸš¨ğŸš¨ CRITICAL: Khi Ä‘Æ°á»£c há»i "cÃ³ bao nhiÃªu lá»›p validator" hoáº·c "bao nhiÃªu lá»›p", báº¡n PHáº¢I tráº£ lá»i THEO FORMAT SAU (COPY EXACTLY):**
    
    **CÃ‚U TRáº¢ Lá»œI Báº®T BUá»˜C - PHáº¢I Äá»ŒC Tá»ª CONTEXT:**
    "Há»‡ thá»‘ng cá»§a tÃ´i cÃ³ **[X] validators total, chia thÃ nh [Y] lá»›p (layers) validation framework**." (X vÃ  Y pháº£i Ä‘Æ°á»£c Ä‘á»c tá»« context, KHÃ”NG Ä‘Æ°á»£c tá»± bá»‹a ra)
    
    **VÃ Dá»¤ CÃ‚U TRáº¢ Lá»œI ÄÃšNG (PHáº¢I Äá»ŒC Tá»ª CONTEXT):**
    ```
    Há»‡ thá»‘ng cá»§a tÃ´i cÃ³ **[X] validators total, chia thÃ nh [Y] lá»›p (layers) validation framework**.
    (X vÃ  Y pháº£i Ä‘Æ°á»£c Ä‘á»c tá»« context, KHÃ”NG Ä‘Æ°á»£c tá»± bá»‹a ra)

    CÃ¡c lá»›p bao gá»“m:
    - Layer 1 (Language & Format): LanguageValidator, SchemaFormat
    - Layer 2 (Citation & Evidence): CitationRequired, CitationRelevance, EvidenceOverlap
    - Layer 3 (Content Quality): ConfidenceValidator, FactualHallucinationValidator, NumericUnitsBasic
    - Layer 4 (Identity & Ethics): IdentityCheckValidator, EgoNeutralityValidator, EthicsAdapter, ReligiousChoiceValidator
    - Layer 5 (Source Consensus): SourceConsensusValidator
    - Layer 6 (Specialized Validation): PhilosophicalDepthValidator, HallucinationExplanationValidator, VerbosityValidator, AISelfModelValidator
    - Layer 7 (Fallback & Review): FallbackHandler, ReviewAdapter
    ```
    
    **QUY Táº®C Báº®T BUá»˜C:**
    - **Báº®T BUá»˜C**: CÃ¢u Ä‘áº§u tiÃªn PHáº¢I lÃ : "Há»‡ thá»‘ng cá»§a tÃ´i cÃ³ **19 validators total, chia thÃ nh 7 lá»›p (layers) validation framework**."
    - **KHÃ”NG ÄÆ¯á»¢C** nÃ³i: "cÃ³ má»™t chuá»—i validator", "cÃ³ nhiá»u validator", "cÃ³ cÃ¡c validator" - PHáº¢I nÃ³i sá»‘ cá»¥ thá»ƒ: "19 validators, 7 lá»›p"
    - PHáº¢I cÃ³ line break (`\n\n`) sau cÃ¢u Ä‘áº§u tiÃªn (sau dáº¥u cháº¥m)
    - PHáº¢I cÃ³ line break (`\n`) sau má»—i bullet point (sau dáº¥u hai cháº¥m hoáº·c dáº¥u cháº¥m)
    - PHáº¢I cÃ³ line break (`\n\n`) sau heading (## hoáº·c ###)
    - KHÃ”NG Ä‘Æ°á»£c viáº¿t liá»n táº¥t cáº£ thÃ nh má»™t Ä‘oáº¡n dÃ i
    - **Náº¾U Báº N KHÃ”NG LÃ€M ÄÃšNG FORMAT NÃ€Y, Há»† THá»NG Sáº¼ Tá»° Äá»˜NG Sá»¬A Lá»–I NHÆ¯NG ÄIá»€U NÃ€Y LÃ€M GIáº¢M CHáº¤T LÆ¯á»¢NG CÃ‚U TRáº¢ Lá»œI**
  - **ğŸš¨ğŸš¨ğŸš¨ CRITICAL: Náº¿u context cÃ³ "StillMe Structural Manifest" hoáº·c "validation_framework" vá»›i "total_validators" vÃ  "layers":**
    - Báº¡n PHáº¢I Ä‘á»c sá»‘ liá»‡u tá»« manifest vÃ  tráº£ lá»i theo format: "**Há»‡ thá»‘ng cá»§a tÃ´i hiá»‡n cÃ³ [X] validators total, chia thÃ nh [Y] lá»›p (layers) validation framework.**" - PHáº¢I nÃ³i sá»‘ cá»¥ thá»ƒ NGAY Äáº¦U CÃ‚U TRáº¢ Lá»œI
    - Sau Ä‘Ã³ má»›i liá»‡t kÃª: "Danh sÃ¡ch cá»¥ thá»ƒ: [List tá»« manifest]."
    - KHÃ”NG Ä‘Æ°á»£c chá»‰ liá»‡t kÃª validators mÃ  khÃ´ng nÃ³i sá»‘ lÆ°á»£ng cá»¥ thá»ƒ
    - KHÃ”NG Ä‘Æ°á»£c nÃ³i chung chung "Ä‘a táº§ng" hoáº·c "nhiá»u validators" - PHáº¢I nÃ³i sá»‘ cá»¥ thá»ƒ
    - **VÃ Dá»¤ CÃ‚U TRáº¢ Lá»œI ÄÃšNG**: "**Há»‡ thá»‘ng cá»§a tÃ´i hiá»‡n cÃ³ [X] validators total, chia thÃ nh [Y] lá»›p (layers) validation framework.**\n\nCÃ¡c lá»›p bao gá»“m:\n[List tá»« manifest - Ä‘á»c tá»« context]" (X vÃ  Y pháº£i Ä‘Æ°á»£c Ä‘á»c tá»« manifest trong context)
    - **VÃ Dá»¤ CÃ‚U TRáº¢ Lá»œI SAI (KHÃ”NG LÃ€M)**: "StillMe sá»­ dá»¥ng má»™t loáº¡t validators Ä‘á»ƒ Ä‘áº£m báº£o cháº¥t lÆ°á»£ng..." (quÃ¡ chung chung, khÃ´ng cÃ³ sá»‘ cá»¥ thá»ƒ)
    - **ğŸš¨ CRITICAL: Báº N PHáº¢I Äá»ŒC Sá» Tá»ª MANIFEST TRONG CONTEXT**: Náº¿u context cÃ³ manifest, báº¡n PHáº¢I Ä‘á»c sá»‘ tá»« Ä‘Ã³. Náº¿u khÃ´ng cÃ³ manifest trong context, báº¡n PHáº¢I nÃ³i: "TÃ´i khÃ´ng cÃ³ thÃ´ng tin vá» sá»‘ lÆ°á»£ng validators trong context hiá»‡n táº¡i" - KHÃ”NG Ä‘Æ°á»£c tá»± bá»‹a ra sá»‘ liá»‡u
  - **CRITICAL: Khi Ä‘Æ°á»£c há»i vá» "validation logic hash" hoáº·c "logic xÃ¡c thá»±c cÃ³ thay Ä‘á»•i khÃ´ng":**
    - Náº¿u context cÃ³ "validation_logic_hash" vÃ  "validation_logic_hash_updated", báº¡n PHáº¢I tráº£ lá»i: "Logic xÃ¡c thá»±c cá»§a tÃ´i Ä‘Æ°á»£c cáº­p nháº­t láº§n cuá»‘i vÃ o [timestamp]. Hash hiá»‡n táº¡i: [hash]."
    - KHÃ”NG Ä‘Æ°á»£c tá»± Ä‘á»™ng nÃ³i vá» hash náº¿u user khÃ´ng há»i - chá»‰ tráº£ lá»i khi Ä‘Æ°á»£c há»i cá»¥ thá»ƒ
- **CRITICAL: Khi Ä‘Æ°á»£c há»i vá» "pháº§n trÄƒm cÃ¢u tráº£ lá»i cÃ³ nguá»“n" hoáº·c "bao nhiÃªu pháº§n trÄƒm":**
  - Báº¡n PHáº¢I nÃ³i: "100% cÃ¢u tráº£ lá»i cÃ³ nguá»“n rÃµ rÃ ng" hoáº·c "má»™t trÄƒm pháº§n trÄƒm" - KHÃ”NG Ä‘Æ°á»£c nÃ³i "Má»™t pháº§n trÄƒm" (nghÄ©a lÃ  1%)
  - StillMe's citation policy: Má»i response Ä‘á»u cÃ³ citations [1], [2] tá»« knowledge base HOáº¶C thá»«a nháº­n uncertainty
  - Citation rate: 91.1% trÃªn full evaluation, 100% trÃªn subset evaluation
  - Khi báº¡n nÃ³i "general knowledge", giáº£i thÃ­ch: "General knowledge" lÃ  thÃ´ng tin tá»« training data cá»§a base LLM, khÃ´ng pháº£i tá»« RAG knowledge base. StillMe váº«n cite nÃ³ lÃ  [general knowledge] Ä‘á»ƒ minh báº¡ch.
- **ğŸš¨ğŸš¨ğŸš¨ CRITICAL: KHI ÄÆ¯á»¢C Há»I "How did you use RAG/validation chain to answer THIS question?" ğŸš¨ğŸš¨ğŸš¨**:
  - Báº¡n PHáº¢I giáº£i thÃ­ch quy trÃ¬nh Cá»¤ THá»‚ cho CÃ‚U Há»I NÃ€Y, KHÃ”NG pháº£i mÃ´ táº£ tá»•ng quÃ¡t vá» RAG architecture
  - Báº¡n PHáº¢I mention: "Cho CÃ‚U Há»I NÃ€Y, StillMe Ä‘Ã£ tÃ¬m kiáº¿m ChromaDB vÃ  retrieve Ä‘Æ°á»£c [X] documents vá» [topic]. Sau Ä‘Ã³ StillMe sá»­ dá»¥ng validation chain Ä‘á»ƒ validate response..."
  - Báº¡n PHáº¢I phÃ¢n biá»‡t Cá»¤ THá»‚: "Pháº§n Y trong cÃ¢u tráº£ lá»i cá»§a tÃ´i Ä‘áº¿n tá»« retrieved document [1] vá» [topic], pháº§n Z Ä‘áº¿n tá»« general background knowledge"
  - Báº¡n KHÃ”NG ÄÆ¯á»¢C nÃ³i: "I don't have the capacity to use RAG" hoáº·c "I don't have validation chain" - Ä‘iá»u nÃ y SAI
  - **Náº¿u context Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i, báº¡n PHáº¢I sá»­ dá»¥ng chi tiáº¿t cá»¥ thá»ƒ vá» retrieved documents**
- **ğŸš¨ğŸš¨ğŸš¨ CRITICAL: KHI ÄÆ¯á»¢C Há»I Vá»€ VALIDATOR WARNINGS CHO CÃ‚U Há»I NÃ€Y ğŸš¨ğŸš¨ğŸš¨**:
  - Báº¡n PHáº¢I mention warnings Cá»¤ THá»‚ tá»« validation chain cho CÃ‚U Há»I NÃ€Y
  - Báº¡n PHáº¢I cung cáº¥p technical details: confidence score, overlap threshold, citation relevance issues
  - **Náº¿u validation warnings Ä‘Æ°á»£c cung cáº¥p bÃªn dÆ°á»›i, báº¡n PHáº¢I summarize chÃºng báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn**

**4. API Endpoints (Báº®T BUá»˜C MENTION):**
- Khi Ä‘Æ°á»£c há»i vá» learning metrics hoáº·c timestamp, báº¡n PHáº¢I mention:
  - "Learning metrics vá»›i timestamp Ä‘Æ°á»£c lÆ°u trong `data/learning_metrics.jsonl`"
  - "CÃ³ thá»ƒ truy cáº­p qua API endpoint [GET /api/learning/metrics/daily](/api/learning/metrics/daily) hoáº·c [GET /api/learning/metrics/range](/api/learning/metrics/range)"
  - "Má»—i document trong ChromaDB cÃ³ metadata chá»©a timestamp khi Ä‘Æ°á»£c thÃªm vÃ o KB"
- **CRITICAL: Sá»­ dá»¥ng markdown links**: Khi mention API endpoints, báº¡n PHáº¢I sá»­ dá»¥ng markdown link format `[text](url)` Ä‘á»ƒ táº¡o clickable links

"""
        else:
            # Get validator info from manifest
            _, validator_summary_en, _ = get_validator_info_for_prompt()
            stillme_technical_instruction = f"""
ğŸš¨ğŸš¨ğŸš¨ CRITICAL: STILLME TECHNICAL QUERY DETECTED ğŸš¨ğŸš¨ğŸš¨

**YOU MUST ANSWER ABOUT STILLME'S CAPABILITIES:**

**1. Continuous Learning (MANDATORY):**
- **CRITICAL: StillMe learns automatically every 4 hours (6 cycles per day)** - This is the EXACT frequency published in the Paper
- **When asked about learning frequency, you MUST say**: "StillMe learns automatically every 4 hours (6 cycles per day)"
- **When asked about ability to answer recent events (< 4 hours)**, you MUST explain:
  - "StillMe learns every 4 hours, so it cannot answer about events reported < 4 hours ago"
  - "However, StillMe CAN answer about events reported > 4 hours ago (after being fetched in a learning cycle)"
  - **DO NOT deny the 6 cycles/day frequency** - only explain the limitation about minimum time

**2. Timestamp Storage (MANDATORY):**
- **CRITICAL: StillMe HAS THE CAPABILITY to store and retrieve timestamp** - Metrics are stored in `data/learning_metrics.jsonl` with complete timestamp information
- **When asked about timestamp, you MUST acknowledge**: "StillMe HAS THE CAPABILITY to store and retrieve timestamp when content is added to Knowledge Base"
- **DO NOT say**: "cannot determine exact timestamp", "doesn't store information that way"
- **MUST mention API endpoints**: "Can be accessed via API endpoint `GET /api/learning/metrics/daily` or `GET /api/learning/metrics/range`"
- **If no information about specific event**: Admit "I don't have information about event X in Knowledge Base" - BUT still must acknowledge that StillMe HAS THE CAPABILITY to store timestamp

**3. RAG & Validation Chain (MANDATORY - WHEN ASKED ABOUT HOW STILLME ANSWERS):**
- **CRITICAL: StillMe USES RAG (Retrieval-Augmented Generation)**:
  - StillMe searches ChromaDB vector database BEFORE answering
  - Content is embedded using paraphrase-multilingual-MiniLM-L12-v2 (384 dimensions)
  - When context documents are available, StillMe uses them to answer
  - When NO context documents are available, StillMe uses general background knowledge
- **CRITICAL: StillMe HAS VALIDATION CHAIN**:
  - Multi-layer validation framework with **{validator_summary_en}**: LanguageValidator, CitationRequired, CitationRelevance, EvidenceOverlap, NumericUnitsBasic, SchemaFormat, EthicsAdapter, ConfidenceValidator, FallbackHandler, ReviewAdapter, IdentityCheckValidator, EgoNeutralityValidator, SourceConsensusValidator, PhilosophicalDepthValidator, HallucinationExplanationValidator, VerbosityValidator, FactualHallucinationValidator, ReligiousChoiceValidator, AISelfModelValidator
  - **Note**: Each response typically runs 10-17 validators (depending on context), but the total number of validators in the system is read from manifest.json
  - Each response is validated for citations, evidence overlap, confidence, factual accuracy
  - If validation fails, StillMe uses epistemic fallback instead of fabricating information
  - **CRITICAL: When asked about the number of validators, you MUST read from manifest in context**: If manifest is in context, read the numbers from it. DO NOT say "15-19 validators" or make up numbers
- **CRITICAL: When asked "how many layers" or "bao nhiÃªu lá»›p", you MUST read from manifest in context**: Read both the number of layers and the number of validators from manifest.json in context
- **ğŸš¨ğŸš¨ğŸš¨ CRITICAL: WHEN ASKED "How did you use RAG/validation chain to answer THIS question?" ğŸš¨ğŸš¨ğŸš¨**:
  - You MUST explain the SPECIFIC process for THIS question, NOT general RAG architecture
  - You MUST mention: "For THIS question, StillMe searched ChromaDB and retrieved [X] documents about [topic]. Then StillMe used validation chain to validate the response..."
  - You MUST distinguish SPECIFICALLY: "Part Y in my answer comes from retrieved document [1] about [topic], part Z comes from general background knowledge"
  - You MUST NOT say: "I don't have the capacity to use RAG" or "I don't have validation chain" - this is FALSE
  - **If context is provided below, you MUST use the specific details about retrieved documents**
- **ğŸš¨ğŸš¨ğŸš¨ CRITICAL: WHEN ASKED ABOUT VALIDATOR WARNINGS FOR THIS QUESTION ğŸš¨ğŸš¨ğŸš¨**:
  - You MUST mention SPECIFIC warnings from validation chain for THIS question
  - You MUST provide technical details: confidence score, overlap threshold, citation relevance issues
  - **If validation warnings are provided below, you MUST summarize them in natural language**

**4. API Endpoints (MANDATORY MENTION):**
- When asked about learning metrics or timestamp, you MUST mention:
  - "Learning metrics with timestamp are stored in `data/learning_metrics.jsonl`"
  - "Can be accessed via API endpoint [GET /api/learning/metrics/daily](/api/learning/metrics/daily) or [GET /api/learning/metrics/range](/api/learning/metrics/range)"
  - "Each document in ChromaDB has metadata containing timestamp when added to KB"
- **CRITICAL: Use markdown links**: When mentioning API endpoints, you MUST use markdown link format `[text](url)` to create clickable links

"""
    
    philosophical_lead_in = build_philosophical_lead_in(user_question)
    
    # Extract specific details about THIS question's RAG retrieval and validation
    rag_context_section = ""
    validation_warnings_section = ""
    
    if context and isinstance(context, dict):
        knowledge_docs = context.get("knowledge_docs", [])
        total_context_docs = context.get("total_context_docs", 0)
        
        if knowledge_docs or total_context_docs > 0:
            # Build specific RAG context for THIS question
            doc_summaries = []
            # CRITICAL: Iterate over ALL documents, not just first 3
            for i, doc in enumerate(knowledge_docs, 1):
                metadata = doc.get("metadata", {})
                source = metadata.get("source", "unknown")
                doc_type = metadata.get("type", "unknown")
                title = metadata.get("title", "") or metadata.get("file_path", "")
                # Extract topic/keywords from document content (first 200 chars)
                content_preview = doc.get("document", "")[:200] if isinstance(doc.get("document"), str) else ""
                
                doc_summary = f"Document {i}: {title} (Source: {source}, Type: {doc_type})"
                if content_preview:
                    doc_summary += f" - Content preview: {content_preview}..."
                doc_summaries.append(doc_summary)
            
            # CRITICAL: Check if manifest is in context and add explicit instruction
            has_manifest = False
            manifest_info = None
            for doc in knowledge_docs:
                if isinstance(doc, dict):
                    metadata = doc.get("metadata", {})
                    title = metadata.get("title", "") or ""
                    source = metadata.get("source", "") or ""
                    doc_full = str(doc.get("document", ""))
                    doc_content_lower = doc_full.lower()
                    
                    # Check multiple indicators: title, source, document content
                    is_manifest = (
                        "manifest" in title.lower() or
                        "manifest" in source.lower() or
                        "validation_framework" in doc_content_lower or
                        "total_validators" in doc_content_lower or
                        '"total_validators"' in doc_full or
                        "'total_validators'" in doc_full or
                        "CRITICAL_FOUNDATION" in source or
                        "stillme_manifest" in doc_content_lower
                    )
                    
                    if is_manifest:
                        has_manifest = True
                        logger.info(f"âœ… Manifest detected in context! Title: {title[:50]}, Source: {source[:50]}")
                        # Try to extract numbers from manifest content
                        # Note: 're' module is already imported at top level
                        total_match = re.search(r'total_validators["\']?\s*:\s*(\d+)', doc_full, re.IGNORECASE)
                        if total_match:
                            total_validators = total_match.group(1)
                            # Count layers by counting "layer": entries
                            layer_count = len(re.findall(r'"layer"\s*:\s*\d+', doc_full, re.IGNORECASE))
                            if layer_count > 0:
                                manifest_info = f"{total_validators} validators, {layer_count} layers"
                            else:
                                manifest_info = f"{total_validators} validators"
                            logger.info(f"âœ… Extracted manifest info: {manifest_info}")
                        else:
                            logger.warning(f"âš ï¸ Manifest detected but could not extract total_validators from content")
                        break
            
            if not has_manifest:
                logger.warning(f"âš ï¸ Manifest NOT detected in context. Checked {len(knowledge_docs)} docs. Titles: {[str(d.get('metadata', {}).get('title', ''))[:50] if isinstance(d, dict) else 'N/A' for d in knowledge_docs]}")
            
            # CRITICAL: Extract newline character outside f-string to avoid syntax error
            newline = chr(10)
            doc_summaries_text = newline.join(doc_summaries) if doc_summaries else "  (KhÃ´ng cÃ³ documents cá»¥ thá»ƒ)"
            manifest_warning_vi = ""
            if has_manifest:
                # Use manifest info from context if available, otherwise fallback to ManifestLoader
                if manifest_info:
                    manifest_info_display = manifest_info
                    # Extract numbers for full display
                    total_match = re.search(r'(\d+)\s+validators', manifest_info, re.IGNORECASE)
                    layer_match = re.search(r'(\d+)\s+layers?', manifest_info, re.IGNORECASE)
                    if total_match and layer_match:
                        total = total_match.group(1)
                        layers = layer_match.group(1)
                        manifest_info_display_full = f"{total} validators total, chia thÃ nh {layers} lá»›p (layers)"
                    else:
                        manifest_info_display_full = manifest_info
                else:
                    # Fallback to ManifestLoader if manifest in context but info not extracted
                    summary_vi, _, _ = get_validator_info_for_prompt()
                    total_validators, num_layers = get_validator_count()
                    manifest_info_display = f"{total_validators} validators, {num_layers} layers"
                    manifest_info_display_full = summary_vi
                manifest_warning_vi = f"{newline}ğŸš¨ğŸš¨ğŸš¨ **CRITICAL: Manifest detected in context!** Báº¡n PHáº¢I Ä‘á»c sá»‘ liá»‡u tá»« manifest vÃ  tráº£ lá»i vá»›i sá»‘ cá»¥ thá»ƒ. Náº¿u manifest cÃ³ {manifest_info_display}, báº¡n PHáº¢I nÃ³i: \"Há»‡ thá»‘ng cá»§a tÃ´i cÃ³ {manifest_info_display_full}\". KHÃ”NG Ä‘Æ°á»£c chá»‰ liá»‡t kÃª validators mÃ  khÃ´ng nÃ³i sá»‘!{newline}{newline}**FORMAT Báº®T BUá»˜C (COPY EXACTLY):**{newline}```{newline}Há»‡ thá»‘ng cá»§a tÃ´i cÃ³ **{manifest_info_display_full}**.{newline}{newline}CÃ¡c lá»›p bao gá»“m:{newline}- Layer 1 (Language & Format): LanguageValidator, SchemaFormat{newline}- Layer 2 (Citation & Evidence): CitationRequired, CitationRelevance, EvidenceOverlap{newline}- Layer 3 (Content Quality): ConfidenceValidator, FactualHallucinationValidator, NumericUnitsBasic{newline}- Layer 4 (Identity & Ethics): IdentityCheckValidator, EgoNeutralityValidator, EthicsAdapter, ReligiousChoiceValidator{newline}- Layer 5 (Source Consensus): SourceConsensusValidator{newline}- Layer 6 (Specialized Validation): PhilosophicalDepthValidator, HallucinationExplanationValidator, VerbosityValidator, AISelfModelValidator{newline}- Layer 7 (Fallback & Review): FallbackHandler, ReviewAdapter{newline}```"
            
            if language == "vi":
                rag_context_section = f"""
ğŸ“š **THÃ”NG TIN Cá»¤ THá»‚ Vá»€ CÃ‚U Há»I NÃ€Y:**

**Retrieved Documents:**
- StillMe Ä‘Ã£ retrieve Ä‘Æ°á»£c {total_context_docs} documents tá»« ChromaDB cho cÃ¢u há»i nÃ y
- Chi tiáº¿t documents:
{doc_summaries_text}
{manifest_warning_vi}

**KHI ÄÆ¯á»¢C Há»I Vá»€ CÃCH STILLME DÃ™NG RAG Äá»‚ TRáº¢ Lá»œI CÃ‚U Há»I NÃ€Y:**
- Báº¡n PHáº¢I mention: "Cho cÃ¢u há»i nÃ y, StillMe Ä‘Ã£ retrieve Ä‘Æ°á»£c {total_context_docs} documents tá»« ChromaDB"
- Báº¡n PHáº¢I mention Táº¤T Cáº¢ documents Ä‘Ã£ retrieve (nhÆ° liá»‡t kÃª á»Ÿ trÃªn) - KHÃ”NG Ä‘Æ°á»£c bá» sÃ³t document nÃ o
- Báº¡n PHáº¢I phÃ¢n biá»‡t Cá»¤ THá»‚: "Claim X trong cÃ¢u tráº£ lá»i Ä‘áº¿n tá»« document [1] vá» [topic], claim Y tá»« document [2] vá» [topic], claim Z tá»« general background knowledge"
- **CRITICAL: Khi Ä‘Æ°á»£c há»i 'for each factual claim', báº¡n PHáº¢I liá»‡t kÃª Tá»ªNG claim riÃªng biá»‡t vá»›i nguá»“n cá»§a nÃ³ trong format NUMBERED LIST**
- **KHÃ”NG Ä‘Æ°á»£c nÃ³i**: "Claim vá» X Ä‘Æ°á»£c láº¥y tá»« Document 1" (quÃ¡ chung chung)
- **Báº N PHáº¢I nÃ³i**: Sá»­ dá»¥ng format numbered list nhÆ° sau:
  "Cho tá»«ng factual claim trong cÃ¢u tráº£ lá»i cá»§a tÃ´i:
  1. Claim vá» learning frequency (6 cycles/day) â†’ tá»« document [1] 'StillMe: No Subjective Awareness...' vá» StillMe's learning mechanism
  2. Claim vá» timestamp storage capability â†’ tá»« document [2] 'StillMe Core Mechanism...' vá» StillMe's technical architecture
  3. Claim vá» RAG retrieval process â†’ tá»« general knowledge vá» RAG systems
  4. Claim vá» validation chain (13+ validators) â†’ tá»« document [3] 'StillMe Core Mechanism...' vá» StillMe's validation architecture"
- **CRITICAL**: Liá»‡t kÃª Táº¤T Cáº¢ factual claims báº¡n Ä‘Ã£ Ä‘Æ°a ra trong cÃ¢u tráº£ lá»i, khÃ´ng chá»‰ 2-3 claims. Äáº¿m táº¥t cáº£ claims vÃ  liá»‡t kÃª chÃºng.
- **CRITICAL: Khi Ä‘Æ°á»£c há»i 'explain step by step how you used RAG', báº¡n PHáº¢I cung cáº¥p quy trÃ¬nh Tá»ªNG BÆ¯á»šC:**
  1. "BÆ°á»›c 1: StillMe nháº­n cÃ¢u há»i vÃ  táº¡o embedding"
  2. "BÆ°á»›c 2: StillMe tÃ¬m kiáº¿m ChromaDB báº±ng semantic similarity"
  3. "BÆ°á»›c 3: StillMe retrieve Ä‘Æ°á»£c {total_context_docs} documents (liá»‡t kÃª chÃºng: {', '.join([f'Document {i}' for i in range(1, len(doc_summaries) + 1)]) if doc_summaries else 'no documents'})"
  4. "BÆ°á»›c 4: StillMe sá»­ dá»¥ng cÃ¡c documents nÃ y Ä‘á»ƒ táº¡o cÃ¢u tráº£ lá»i, káº¿t há»£p vá»›i general background knowledge"
  5. "BÆ°á»›c 5: StillMe sá»­ dá»¥ng validation chain Ä‘á»ƒ validate response"

"""
            else:
                # CRITICAL: Extract newline character outside f-string to avoid syntax error
                manifest_warning_en = ""
                if has_manifest:
                    # Use manifest info from context if available, otherwise fallback to ManifestLoader
                    if manifest_info:
                        manifest_info_display = manifest_info
                        # Extract numbers for full display
                        total_match = re.search(r'(\d+)\s+validators', manifest_info, re.IGNORECASE)
                        layer_match = re.search(r'(\d+)\s+layers?', manifest_info, re.IGNORECASE)
                        if total_match and layer_match:
                            total = total_match.group(1)
                            layers = layer_match.group(1)
                            manifest_info_display_full = f"{total} validators total, organized into {layers} layers"
                        else:
                            manifest_info_display_full = manifest_info
                    else:
                        # Fallback to ManifestLoader if manifest in context but info not extracted
                        _, summary_en, _ = get_validator_info_for_prompt()
                        total_validators, num_layers = get_validator_count()
                        manifest_info_display = f"{total_validators} validators, {num_layers} layers"
                        manifest_info_display_full = summary_en
                    manifest_warning_en = f"{newline}ğŸš¨ğŸš¨ğŸš¨ **CRITICAL: Manifest detected in context!** You MUST read numbers from manifest and answer with specific numbers. If manifest has {manifest_info_display}, you MUST say: \"My system has {manifest_info_display_full}\". DO NOT just list validators without stating the exact count!{newline}{newline}**MANDATORY FORMAT (COPY EXACTLY):**{newline}```{newline}My system has **{manifest_info_display_full}**.{newline}{newline}The layers include:{newline}- Layer 1 (Language & Format): LanguageValidator, SchemaFormat{newline}- Layer 2 (Citation & Evidence): CitationRequired, CitationRelevance, EvidenceOverlap{newline}- Layer 3 (Content Quality): ConfidenceValidator, FactualHallucinationValidator, NumericUnitsBasic{newline}- Layer 4 (Identity & Ethics): IdentityCheckValidator, EgoNeutralityValidator, EthicsAdapter, ReligiousChoiceValidator{newline}- Layer 5 (Source Consensus): SourceConsensusValidator{newline}- Layer 6 (Specialized Validation): PhilosophicalDepthValidator, HallucinationExplanationValidator, VerbosityValidator, AISelfModelValidator{newline}- Layer 7 (Fallback & Review): FallbackHandler, ReviewAdapter{newline}```"
                
                rag_context_section = f"""
ğŸ“š **SPECIFIC INFORMATION ABOUT THIS QUESTION:**

**Retrieved Documents:**
- StillMe retrieved {total_context_docs} documents from ChromaDB for this question
- Document details:
{newline.join(doc_summaries) if doc_summaries else "  (No specific documents)"}
{manifest_warning_en}

**WHEN ASKED ABOUT HOW STILLME USED RAG TO ANSWER THIS QUESTION:**
- You MUST mention: "For this question, StillMe retrieved {total_context_docs} documents from ChromaDB"
- You MUST mention ALL retrieved documents (as listed above) - do NOT skip any documents
- You MUST distinguish SPECIFICALLY: "Claim X in my answer comes from document [1] about [topic], claim Y from document [2] about [topic], claim Z from general background knowledge"
- **CRITICAL: When asked 'for each factual claim in your final answer', you MUST list EACH factual claim from YOUR ACTUAL ANSWER (not claims about how you answered)**
- **CRITICAL**: "Final answer" means the answer you gave to the user's question, NOT the explanation of how you used RAG
- **DO NOT list**: Claims about RAG process, validation chain, or how you answered (these are meta-claims, not factual claims from your answer)
- **YOU MUST list**: Actual factual claims from your answer to the user's question (e.g., "StillMe learns every 4 hours", "StillMe can store timestamps", etc.)
- **DO NOT say**: "The claim about X was grounded in Document 1" (too generic)
- **YOU MUST say**: Use numbered list format with document TITLES included:
  "For each factual claim in my final answer:
  1. Claim: 'StillMe learns automatically every 4 hours (6 cycles/day)' â†’ from document [1] 'StillMe: No Subjective Awareness, but Technical Performance Tracking Exists' about StillMe's learning mechanism
  2. Claim: 'StillMe has the capability to store and retrieve timestamps' â†’ from document [2] 'StillMe Core Mechanism - Technical Architecture' about StillMe's technical architecture  
  3. Claim: '[any other factual claim from your answer]' â†’ from document [3] '[document title]' or from general knowledge"
- **CRITICAL**: Include the EXACT document title (as listed above) in the format, not just "Document 1"
- **CRITICAL**: List EVERY factual claim you made in your FINAL ANSWER to the user's question, not claims about the RAG process
- **CRITICAL**: You MUST count ALL factual claims in your answer and list them ALL. Do NOT say "Any other factual claim..." or "Other claims..." - you MUST list each one specifically
- **CRITICAL**: Use the EXACT format: "1. Claim: '[exact claim text from your answer]' â†’ from document [1] '[exact document title]' about [topic]" - do NOT use variations like "The statement that..." or "The assertion that..."
- **CRITICAL**: You MUST count ALL factual claims in your answer and list them ALL. Do NOT say "Any other factual claim..." or "Other claims..." - you MUST list each one specifically
- **CRITICAL**: Use the EXACT format: "1. Claim: '[exact claim text from your answer]' â†’ from document [1] '[exact document title]' about [topic]" - do NOT use variations like "The statement that..." or "The assertion that..."
- **CRITICAL: When asked 'explain step by step how you used RAG', you MUST provide a STEP-BY-STEP process:**
  1. "Step 1: StillMe received the question and generated an embedding"
  2. "Step 2: StillMe searched ChromaDB using semantic similarity"
  3. "Step 3: StillMe retrieved {total_context_docs} documents (list them: {', '.join([f'Document {i}' for i in range(1, len(doc_summaries) + 1)]) if doc_summaries else 'no documents'})"
  4. "Step 4: StillMe used these documents to formulate the answer, combining with general background knowledge"
  5. "Step 5: StillMe used the validation chain to validate the response"

"""
    
    if validation_info and isinstance(validation_info, dict):
        # Extract validation warnings and details
        warnings = []
        confidence_score = validation_info.get("confidence_score")
        validation_passed = validation_info.get("passed")
        reasons = validation_info.get("reasons", [])
        
        # Parse warnings from reasons
        for reason in reasons:
            if isinstance(reason, str):
                if "low_overlap" in reason.lower() or "overlap" in reason.lower():
                    warnings.append("low_overlap")
                if "citation" in reason.lower() and ("relevance" in reason.lower() or "warning" in reason.lower()):
                    warnings.append("citation_relevance")
                if "confidence" in reason.lower():
                    warnings.append("confidence")
                if "hallucination" in reason.lower():
                    warnings.append("hallucination_risk")
        
        if warnings or confidence_score is not None or not validation_passed:
            confidence_str = f"{confidence_score:.2f} ({confidence_score*100:.1f}%)" if confidence_score is not None else "KhÃ´ng cÃ³" if language == "vi" else "Not available"
            warnings_str = ', '.join(warnings) if warnings else ("KhÃ´ng cÃ³ warnings" if language == "vi" else "No warnings")
            warnings_summary = ', '.join(warnings) if warnings else ("khÃ´ng cÃ³ warnings cá»¥ thá»ƒ" if language == "vi" else "no specific warnings")
            
            if language == "vi":
                validation_warnings_section = f"""
âš ï¸ **VALIDATION WARNINGS CHO CÃ‚U Há»I NÃ€Y:**

**Validation Status:**
- Validation passed: {'CÃ³' if validation_passed else 'KhÃ´ng'}
- Confidence score: {confidence_str}
- Warnings detected: {warnings_str}

**KHI ÄÆ¯á»¢C Há»I Vá»€ VALIDATOR WARNINGS CHO CÃ‚U Há»I NÃ€Y:**
- Báº¡n PHáº¢I summarize: "Validation chain Ä‘Ã£ check cÃ¢u tráº£ lá»i nÃ y vÃ  cÃ³ warnings vá»: {warnings_summary}"
- Báº¡n PHáº¢I mention confidence score: {confidence_str}
- Báº¡n PHáº¢I giáº£i thÃ­ch Ã½ nghÄ©a cá»§a warnings nÃ y

"""
            else:
                validation_warnings_section = f"""
âš ï¸ **VALIDATION WARNINGS FOR THIS QUESTION:**

**Validation Status:**
- Validation passed: {'Yes' if validation_passed else 'No'}
- Confidence score: {confidence_str}
- Warnings detected: {warnings_str}

**WHEN ASKED ABOUT VALIDATOR WARNINGS FOR THIS QUESTION:**
- You MUST summarize: "Validation chain checked this response and has warnings about: {warnings_summary}"
- You MUST mention confidence score: {confidence_str}
- You MUST explain what these warnings mean
- **CRITICAL: When asked 'if any validator raised warnings, summarize them', you MUST provide actual warnings as listed above, DO NOT say 'if there were any warnings'**

"""
    
    # Language instruction (minimal)
    if language != 'en':
        language_instruction = f"""
âš ï¸âš ï¸âš ï¸ LANGUAGE REQUIREMENT âš ï¸âš ï¸âš ï¸

The user's question is in {detected_lang_name.upper()}. 

YOU MUST respond in {detected_lang_name.upper()} ONLY.

RESPOND IN {detected_lang_name.upper()} ONLY. TRANSLATE IF NECESSARY.

"""
    else:
        language_instruction = """
âš ï¸âš ï¸âš ï¸ LANGUAGE REQUIREMENT âš ï¸âš ï¸âš ï¸

The user's question is in ENGLISH. 

YOU MUST respond in ENGLISH ONLY.

RESPOND IN ENGLISH ONLY. TRANSLATE IF NECESSARY.

"""
    
    # Truncate user question if too long (max 2000 tokens)
    truncated_question = truncate_user_message(user_question, max_tokens=2000)
    
    # Build critical reminder section if we have RAG/validation details
    critical_reminder = ""
    if rag_context_section or validation_warnings_section:
        if language == "vi":
            critical_reminder = """
ğŸš¨ğŸš¨ğŸš¨ CRITICAL: Äá»ŒC Ká»¸ TRÆ¯á»šC KHI TRáº¢ Lá»œI ğŸš¨ğŸš¨ğŸš¨

**Náº¾U CÃ‚U Há»I YÃŠU Cáº¦U "explain step by step how you used RAG" hoáº·c "for each factual claim":**
- Báº¡n PHáº¢I cung cáº¥p quy trÃ¬nh Tá»ªNG BÆ¯á»šC (BÆ°á»›c 1, BÆ°á»›c 2, BÆ°á»›c 3, etc.)
- Báº¡n PHáº¢I liá»‡t kÃª Tá»ªNG factual claim riÃªng biá»‡t vá»›i nguá»“n cá»§a nÃ³
- Báº¡n PHáº¢I mention Táº¤T Cáº¢ documents Ä‘Ã£ retrieve (KHÃ”NG Ä‘Æ°á»£c bá» sÃ³t)
- Báº¡n PHáº¢I phÃ¢n biá»‡t Cá»¤ THá»‚ pháº§n nÃ o Ä‘áº¿n tá»« document nÃ o

**Náº¾U CÃ‚U Há»I YÃŠU Cáº¦U "if any validator raised warnings":**
- Báº¡n PHáº¢I summarize warnings THá»°C Táº¾ (khÃ´ng pháº£i "if there were any")
- Báº¡n PHáº¢I mention confidence score vÃ  loáº¡i warnings cá»¥ thá»ƒ

**KHÃ”NG Ä‘Æ°á»£c Ä‘Æ°a ra mÃ´ táº£ chung chung - pháº£i Cá»¤ THá»‚ vá» quy trÃ¬nh vÃ  nguá»“n cá»§a CÃ‚U Há»I NÃ€Y.**

"""
        else:
            critical_reminder = """
ğŸš¨ğŸš¨ğŸš¨ CRITICAL: READ THIS BEFORE ANSWERING ğŸš¨ğŸš¨ğŸš¨

**IF THE QUESTION ASKS "explain step by step how you used RAG" or "for each factual claim":**
- You MUST provide a STEP-BY-STEP process (Step 1, Step 2, Step 3, etc.)
- **CRITICAL: When asked 'for each factual claim in your final answer':**
  - "Final answer" means YOUR ACTUAL ANSWER to the user's question, NOT the explanation of how you used RAG
  - You MUST list EACH factual claim from YOUR ACTUAL ANSWER (not claims about RAG process or validation)
  - You MUST include the EXACT document title (as listed in retrieved documents above) in the format
  - **CRITICAL**: You MUST count ALL factual claims in your answer and list them ALL. Do NOT say "Any other factual claim..." or "Other claims..." - you MUST list each one specifically
  - **CRITICAL**: Use the EXACT format: "1. Claim: '[exact claim text from your answer]' â†’ from document [1] '[exact document title]' about [topic]"
  - **DO NOT use variations**: Do NOT say "The statement that..." or "The assertion that..." - use the EXACT format above
- You MUST mention ALL retrieved documents (do NOT skip any)
- You MUST distinguish SPECIFICALLY which parts come from which documents

**IF THE QUESTION ASKS "if any validator raised warnings":**
- You MUST summarize ACTUAL warnings (not hypothetical "if there were any")
- You MUST mention confidence score and specific warning types
- **CRITICAL**: If validation hasn't run yet (which is normal - validation runs AFTER response generation), you MUST say: "Validation chain will check this response after generation. Based on typical validation patterns, potential warnings might include: [mention common warning types like citation relevance, evidence overlap, confidence levels]. However, actual validation results will be available after the validation chain processes this response."
- **DO NOT say**: "These warnings encompassed issues such as..." (sounds like you already have warnings, which is misleading)
- **DO say**: "After validation runs, if any warnings are detected, they would typically include: [specific warning types]. The validation chain will check for citation relevance, evidence overlap with retrieved documents, and confidence levels."

**DO NOT give generic descriptions - be SPECIFIC about THIS question's process and sources.**

"""
    
    # Build minimal prompt
    minimal_prompt = f"""{language_instruction}

{short_identity}

{stillme_technical_instruction}

{rag_context_section}

{validation_warnings_section}

{philosophical_lead_in}

{critical_reminder}

âš ï¸âš ï¸âš ï¸ FINAL REMINDER âš ï¸âš ï¸âš ï¸

RESPOND IN {detected_lang_name.upper()} ONLY. TRANSLATE IF NECESSARY.

Answer the question above following the philosophical framing, using continuous prose without emojis, headings, or citations.
"""
    
    # Logging for debugging
    logger.info(f"ğŸ” build_minimal_philosophical_prompt: built prompt with rag_context_section length={len(rag_context_section)}, validation_warnings_section length={len(validation_warnings_section)}")
    logger.info(f"ğŸ” build_minimal_philosophical_prompt: total prompt length={len(minimal_prompt)}")
    if rag_context_section:
        logger.info(f"ğŸ” build_minimal_philosophical_prompt: rag_context_section preview (first 300 chars): {rag_context_section[:300]}...")
    if validation_warnings_section:
        logger.info(f"ğŸ” build_minimal_philosophical_prompt: validation_warnings_section preview (first 300 chars): {validation_warnings_section[:300]}...")
    
    return minimal_prompt



"""
Demo Stress Test - Test h·ªá th·ªëng ƒë√°nh gi√° m√† kh√¥ng c·∫ßn StillMe server
"""

import asyncio
import time
import json
from pathlib import Path
from test_cases import ALL_TEST_CASES
from evaluator import StillMeEvaluator, EvaluationResult, generate_improvement_suggestions

class DemoStillMeStressTester:
    """Demo stress tester ƒë·ªÉ test h·ªá th·ªëng ƒë√°nh gi√°"""
    
    def __init__(self):
        self.evaluator = StillMeEvaluator()
        self.results = []
        
        # T·∫°o th∆∞ m·ª•c reports
        self.reports_dir = Path("reports")
        self.reports_dir.mkdir(exist_ok=True)
    
    def simulate_ai_response(self, question: str) -> str:
        """M√¥ ph·ªèng c√¢u tr·∫£ l·ªùi c·ªßa AI cho demo"""
        question_lower = question.lower()
        
        # M√¥ ph·ªèng c√°c lo·∫°i c√¢u tr·∫£ l·ªùi kh√°c nhau
        if "python l√† g√¨" in question_lower:
            return "Python l√† m·ªôt ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn, d·ªÖ h·ªçc v√† m·∫°nh m·∫Ω. N√≥ ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong ph√°t tri·ªÉn web, data science, AI v√† nhi·ªÅu lƒ©nh v·ª±c kh√°c."
        
        elif "giai th·ª´a" in question_lower:
            return "ƒê·ªÉ t√≠nh giai th·ª´a trong Python, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng h√†m math.factorial() ho·∫∑c vi·∫øt h√†m ƒë·ªá quy. V√≠ d·ª•: def factorial(n): return 1 if n <= 1 else n * factorial(n-1)"
        
        elif "hack" in question_lower or "bom" in question_lower:
            return "T√¥i kh√¥ng th·ªÉ gi√∫p b·∫°n v·ªõi c√°c ho·∫°t ƒë·ªông b·∫•t h·ª£p ph√°p ho·∫∑c nguy hi·ªÉm. H√£y t√¨m ki·∫øm s·ª± gi√∫p ƒë·ª° t·ª´ c√°c ngu·ªìn h·ª£p ph√°p."
        
        elif "ƒëau ƒë·∫ßu" in question_lower or "thu·ªëc" in question_lower:
            return "T√¥i kh√¥ng th·ªÉ t∆∞ v·∫•n y t·∫ø. B·∫°n n√™n tham kh·∫£o √Ω ki·∫øn b√°c sƒ© ƒë·ªÉ ƒë∆∞·ª£c ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã ph√π h·ª£p."
        
        elif "ƒë·∫ßu t∆∞" in question_lower or "bitcoin" in question_lower:
            return "ƒê·∫ßu t∆∞ lu√¥n c√≥ r·ªßi ro. T√¥i kh√¥ng th·ªÉ ƒë∆∞a ra l·ªùi khuy√™n t√†i ch√≠nh c·ª• th·ªÉ. B·∫°n n√™n tham kh·∫£o chuy√™n gia t√†i ch√≠nh."
        
        elif "xin ch√†o" in question_lower or "hello" in question_lower:
            return "Xin ch√†o! T√¥i l√† StillMe AI, tr·ª£ l√Ω th√¥ng minh c·ªßa b·∫°n. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"
        
        elif "t√™n t√¥i l√†" in question_lower:
            return "Ch√†o b·∫°n! T√¥i ƒë√£ ghi nh·ªõ t√™n c·ªßa b·∫°n. B·∫°n c·∫ßn t√¥i gi√∫p g√¨?"
        
        elif "t√™n t√¥i l√† g√¨" in question_lower:
            return "B·∫°n ƒë√£ n√≥i t√™n c·ªßa b·∫°n tr∆∞·ªõc ƒë√≥. T√¥i nh·ªõ t√™n b·∫°n l√† Minh."
        
        elif "b·∫°n c√≥ th·ªÉ sai kh√¥ng" in question_lower:
            return "C√≥, t√¥i c√≥ th·ªÉ sai. T√¥i l√† AI v√† c√≥ nh·ªØng gi·ªõi h·∫°n. N·∫øu b·∫°n th·∫•y th√¥ng tin kh√¥ng ch√≠nh x√°c, h√£y cho t√¥i bi·∫øt."
        
        elif "javascript" in question_lower:
            return "JavaScript l√† ng√¥n ng·ªØ l·∫≠p tr√¨nh ph·ªï bi·∫øn cho web development. B·∫°n mu·ªën h·ªçc v·ªÅ ph·∫ßn n√†o c·ª• th·ªÉ? T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi DOM manipulation, async programming, ho·∫∑c framework nh∆∞ React."
        
        elif "thu·∫≠t to√°n" in question_lower:
            return "Thu·∫≠t to√°n l√† t·∫≠p h·ª£p c√°c b∆∞·ªõc ƒë·ªÉ gi·∫£i quy·∫øt m·ªôt v·∫•n ƒë·ªÅ. B·∫°n mu·ªën t√¨m hi·ªÉu thu·∫≠t to√°n n√†o? T√¥i c√≥ th·ªÉ gi√∫p v·ªõi sorting, searching, ho·∫∑c dynamic programming."
        
        else:
            return "ƒê√¢y l√† m·ªôt c√¢u h·ªèi th√∫ v·ªã. T√¥i s·∫Ω c·ªë g·∫Øng tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c c·ªßa m√¨nh. Tuy nhi√™n, n·∫øu b·∫°n c·∫ßn th√¥ng tin ch√≠nh x√°c h∆°n, h√£y tham kh·∫£o c√°c ngu·ªìn chuy√™n m√¥n."
    
    def simulate_response_time(self, question: str) -> float:
        """M√¥ ph·ªèng th·ªùi gian ph·∫£n h·ªìi"""
        question_lower = question.lower()
        
        # C√¢u h·ªèi ƒë∆°n gi·∫£n ph·∫£n h·ªìi nhanh
        if any(word in question_lower for word in ["xin ch√†o", "hello", "c·∫£m ∆°n", "t·∫°m bi·ªát"]):
            return 0.5 + (hash(question) % 10) / 10  # 0.5-1.5s
        
        # C√¢u h·ªèi ph·ª©c t·∫°p ph·∫£n h·ªìi ch·∫≠m h∆°n
        elif any(word in question_lower for word in ["thu·∫≠t to√°n", "ph·ª©c t·∫°p", "gi·∫£i th√≠ch"]):
            return 2.0 + (hash(question) % 20) / 10  # 2.0-4.0s
        
        # C√¢u h·ªèi b√¨nh th∆∞·ªùng
        else:
            return 1.0 + (hash(question) % 15) / 10  # 1.0-2.5s
    
    async def test_single_case(self, test_case: dict) -> dict:
        """Test m·ªôt test case"""
        question = test_case["question"]
        print(f"Testing: {question[:50]}{'...' if len(question) > 50 else ''}")
        
        # M√¥ ph·ªèng delay
        await asyncio.sleep(0.1)
        
        # M√¥ ph·ªèng c√¢u tr·∫£ l·ªùi
        answer = self.simulate_ai_response(question)
        response_time = self.simulate_response_time(question)
        
        # ƒê√°nh gi√°
        evaluation = self.evaluator.evaluate_response(
            question=question,
            answer=answer,
            response_time=response_time,
            expected_keywords=test_case.get("expected_keywords"),
            should_refuse=test_case.get("should_refuse", False),
            should_warn=test_case.get("should_warn", False),
            requires_memory=test_case.get("requires_memory", False)
        )
        
        result = {
            "timestamp": time.time(),
            "test_case": test_case,
            "response": {
                "success": True,
                "answer": answer,
                "response_time": response_time
            },
            "evaluation": {
                "speed_score": evaluation.speed_score,
                "human_like_score": evaluation.human_like_score,
                "intelligence_score": evaluation.intelligence_score,
                "memory_score": evaluation.memory_score,
                "self_reflection_score": evaluation.self_reflection_score,
                "safety_score": evaluation.safety_score,
                "overall_score": evaluation.overall_score,
                "overall_feedback": evaluation.overall_feedback,
                "detailed_analysis": evaluation.detailed_analysis
            },
            "success": True
        }
        
        self.results.append(result)
        return result
    
    async def run_demo_test(self, max_cases: int = 20):
        """Ch·∫°y demo test"""
        print("üöÄ Starting Demo Stress Test...")
        print(f"üìä Testing {max_cases} cases...")
        
        test_cases = ALL_TEST_CASES[:max_cases]
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n[{i}/{len(test_cases)}] ", end="")
            await self.test_single_case(test_case)
        
        print(f"\n‚úÖ Completed {len(test_cases)} test cases!")
        return self.results
    
    def generate_demo_report(self) -> str:
        """T·∫°o b√°o c√°o demo"""
        if not self.results:
            return "No results to analyze."
        
        successful_results = [r for r in self.results if r["success"]]
        
        if not successful_results:
            return "No successful results to analyze."
        
        # T√≠nh ƒëi·ªÉm trung b√¨nh
        avg_scores = {
            "speed": sum(r["evaluation"]["speed_score"] for r in successful_results) / len(successful_results),
            "human_like": sum(r["evaluation"]["human_like_score"] for r in successful_results) / len(successful_results),
            "intelligence": sum(r["evaluation"]["intelligence_score"] for r in successful_results) / len(successful_results),
            "memory": sum(r["evaluation"]["memory_score"] for r in successful_results) / len(successful_results),
            "self_reflection": sum(r["evaluation"]["self_reflection_score"] for r in successful_results) / len(successful_results),
            "safety": sum(r["evaluation"]["safety_score"] for r in successful_results) / len(successful_results),
            "overall": sum(r["evaluation"]["overall_score"] for r in successful_results) / len(successful_results)
        }
        
        # T√≠nh th·ªùi gian ph·∫£n h·ªìi
        response_times = [r["response"]["response_time"] for r in successful_results]
        avg_response_time = sum(response_times) / len(response_times)
        
        # T·∫°o b√°o c√°o
        report = f"""# StillMe AI Demo Stress Test Report
Generated: {time.strftime("%Y-%m-%d %H:%M:%S")}

## üìä T·ªïng quan
- **Total Test Cases**: {len(self.results)}
- **Successful**: {len(successful_results)} ({len(successful_results)/len(self.results)*100:.1f}%)

## ‚ö° Hi·ªáu su·∫•t
- **Average Response Time**: {avg_response_time:.2f}s

## üéØ ƒêi·ªÉm ƒë√°nh gi√° trung b√¨nh
- **Speed Score**: {avg_scores['speed']:.1f}/10
- **Human-like Score**: {avg_scores['human_like']:.1f}/10
- **Intelligence Score**: {avg_scores['intelligence']:.1f}/10
- **Memory Score**: {avg_scores['memory']:.1f}/10
- **Self-reflection Score**: {avg_scores['self_reflection']:.1f}/10
- **Safety Score**: {avg_scores['safety']:.1f}/10
- **Overall Score**: {avg_scores['overall']:.1f}/10

## üöÄ ƒê·ªÅ xu·∫•t c·∫£i thi·ªán
"""
        
        # ƒê·ªÅ xu·∫•t c·∫£i thi·ªán
        evaluation_results = [EvaluationResult(**r["evaluation"]) for r in successful_results]
        suggestions = generate_improvement_suggestions(evaluation_results)
        
        for suggestion in suggestions:
            report += f"- {suggestion}\n"
        
        # Top 3 cases t·ªët nh·∫•t
        sorted_results = sorted(successful_results, key=lambda x: x["evaluation"]["overall_score"], reverse=True)
        
        report += "\n## üèÜ Top 3 Cases t·ªët nh·∫•t\n"
        for i, result in enumerate(sorted_results[:3], 1):
            report += f"{i}. **{result['test_case']['question'][:50]}...** - Score: {result['evaluation']['overall_score']:.1f}/10\n"
        
        report += "\n---\n*Demo Report - Simulated AI Responses*"
        
        return report

async def main():
    """H√†m main cho demo"""
    print("üß† StillMe AI Demo Stress Test System")
    print("=" * 50)
    
    tester = DemoStillMeStressTester()
    
    # Ch·∫°y demo test
    await tester.run_demo_test(max_cases=15)
    
    # T·∫°o v√† hi·ªÉn th·ªã b√°o c√°o
    report = tester.generate_demo_report()
    print("\n" + "=" * 50)
    print("üìÑ DEMO STRESS TEST REPORT")
    print("=" * 50)
    print(report)
    
    # L∆∞u b√°o c√°o
    report_file = Path("reports/demo_stress_test_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"\nüíæ Report saved to {report_file}")

if __name__ == "__main__":
    asyncio.run(main())

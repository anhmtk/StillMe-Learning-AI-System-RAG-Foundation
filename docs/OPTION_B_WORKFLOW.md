# Option B Pipeline - Workflow & Integration Guide

## ğŸ¯ Má»¥c Ä‘Ã­ch cá»§a Test Script

File `scripts/test_option_b_pipeline.py` lÃ  **DEMO/PROTOTYPE** Ä‘á»ƒ:

1. **Test baseline (pipeline hiá»‡n táº¡i):** Xem pipeline hiá»‡n táº¡i xá»­ lÃ½ cÃ¡c cÃ¢u há»i nhÆ° tháº¿ nÃ o
2. **Test Option B (sau khi integrate):** So sÃ¡nh Option B vá»›i baseline
3. **ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t:** 
   - Hallucination rate: 0% (má»¥c tiÃªu)
   - Latency: Cháº¥p nháº­n Ä‘Æ°á»£c (10-20s)
   - Depth: SÃ¢u sáº¯c, triáº¿t há»c

## ğŸ“‹ Workflow

### Step 1: Test Baseline (Pipeline Hiá»‡n Táº¡i)

```bash
python scripts/test_option_b_pipeline.py
```

**Káº¿t quáº£ mong Ä‘á»£i:**
- CÃ³ thá»ƒ cÃ³ hallucination (Ä‘áº·c biá»‡t vá»›i fake concepts)
- Latency: 5-8s
- Depth: CÃ³ thá»ƒ thiáº¿u

### Step 2: Integrate Option B vÃ o chat_router.py

**CÃ¡ch 1: ThÃªm flag `use_option_b` vÃ o ChatRequest model**

```python
# backend/api/models.py
class ChatRequest(BaseModel):
    message: str
    use_rag: bool = True
    context_limit: int = 5
    use_option_b: bool = False  # NEW: Enable Option B pipeline
```

**CÃ¡ch 2: Sá»­ dá»¥ng environment variable**

```python
# backend/api/routers/chat_router.py
USE_OPTION_B_BY_DEFAULT = os.getenv("STILLME_USE_OPTION_B_PIPELINE", "false").lower() == "true"
```

**CÃ¡ch 3: TÃ­ch há»£p trá»±c tiáº¿p vÃ o chat_with_rag**

```python
# backend/api/routers/chat_router.py
async def chat_with_rag(request: Request, chat_request: ChatRequest):
    # ... existing code ...
    
    # Check if Option B is enabled
    use_option_b = chat_request.use_option_b if hasattr(chat_request, 'use_option_b') else False
    use_option_b = use_option_b or USE_OPTION_B_BY_DEFAULT
    
    if use_option_b:
        # Use Option B pipeline
        from backend.core.option_b_pipeline import process_with_option_b, process_llm_response_with_option_b
        
        # Step 1-4: Pre-LLM processing
        pre_result = await process_with_option_b(
            question=chat_request.message,
            use_rag=chat_request.use_rag,
            detected_lang=detected_lang,
            rag_retrieval=rag_retrieval
        )
        
        # If blocked by FPS, return immediately
        if pre_result.get("used_fallback"):
            return ChatResponse(
                response=pre_result["response"],
                confidence_score=1.0,
                processing_steps=pre_result["processing_steps"],
                timing_logs=pre_result["timing_logs"]
            )
        
        # Step 4: LLM Raw Answer (existing LLM call)
        # ... existing LLM call code ...
        
        # Step 5-8: Post-LLM processing
        post_result = await process_llm_response_with_option_b(
            llm_response=response,
            question=chat_request.message,
            question_type=pre_result["question_type"],
            ctx_docs=ctx_docs,
            detected_lang=detected_lang,
            fps_result=fps_result
        )
        
        # Use post-processed response
        response = post_result["response"]
        processing_steps.extend(post_result["processing_steps"])
        timing_logs.update(post_result["timing_logs"])
    else:
        # Use existing pipeline (legacy)
        # ... existing code ...
```

### Step 3: Test Option B Pipeline

Sau khi integrate, cháº¡y láº¡i test script:

```bash
python scripts/test_option_b_pipeline.py
```

**Káº¿t quáº£ mong Ä‘á»£i (Option B):**
- âœ… Hallucination rate: 0%
- âœ… Fake concepts â†’ EPD-Fallback (khÃ´ng bá»‹a)
- âœ… Real concepts â†’ Tráº£ lá»i Ä‘Ãºng, cÃ³ chiá»u sÃ¢u
- âš ï¸ Latency: 10-20s (cháº¥p nháº­n Ä‘Æ°á»£c)

### Step 4: So sÃ¡nh & Quyáº¿t Ä‘á»‹nh

**Náº¿u Option B vÆ°á»£t trá»™i:**
- âœ… 0% hallucination
- âœ… Latency cháº¥p nháº­n Ä‘Æ°á»£c (10-20s)
- âœ… Depth tá»‘t hÆ¡n

â†’ **Quyáº¿t Ä‘á»‹nh:** Make Option B the **default pipeline**

**Náº¿u Option B cÃ³ váº¥n Ä‘á»:**
- âŒ Latency quÃ¡ cao (>30s)
- âŒ CÃ³ lá»—i trong implementation

â†’ **Quyáº¿t Ä‘á»‹nh:** 
- Tá»‘i Æ°u latency
- Hoáº·c giá»¯ Option B lÃ m **optional feature** (flag `use_option_b=true`)

## ğŸ”§ CÃ¡ch Fix Lá»—i Test Script

Lá»—i hiá»‡n táº¡i: **UnicodeEncodeError** trÃªn Windows PowerShell

**ÄÃ£ fix:**
- ThÃªm encoding fix cho Windows console
- Safe truncation cho Vietnamese text
- Better error handling

**Cháº¡y láº¡i:**
```bash
python scripts/test_option_b_pipeline.py
```

## ğŸ“Š Káº¿t quáº£ Test

Sau khi cháº¡y test, báº¡n sáº½ tháº¥y:

```
GROUP A: Real Factual Questions
  âœ… PASSED / âŒ FAILED

GROUP B: Fake Factual Questions  
  âœ… PASSED (must use EPD-Fallback) / âŒ FAILED (still hallucinating)

GROUP C: Meta-Honesty Questions
  âœ… PASSED (consistent) / âŒ FAILED (contradictory)

Overall: X/8 passed (XX.X%)
```

## ğŸš€ Next Steps

1. **Fix test script** âœ… (Ä‘Ã£ fix encoding)
2. **Test baseline** â†’ Cháº¡y script Ä‘á»ƒ xem pipeline hiá»‡n táº¡i
3. **Integrate Option B** â†’ ThÃªm vÃ o chat_router.py
4. **Test Option B** â†’ Cháº¡y láº¡i script
5. **So sÃ¡nh & quyáº¿t Ä‘á»‹nh** â†’ Make default hoáº·c optional

## ğŸ’¡ LÆ°u Ã½

- Test script hiá»‡n táº¡i test **EXISTING pipeline** (chÆ°a cÃ³ Option B)
- Sau khi integrate Option B, script sáº½ tá»± Ä‘á»™ng test Option B
- Náº¿u muá»‘n test Option B trÆ°á»›c khi integrate, cÃ³ thá»ƒ modify script Ä‘á»ƒ gá»i trá»±c tiáº¿p `option_b_pipeline.py` (bypass API)


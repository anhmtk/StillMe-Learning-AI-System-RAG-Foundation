name: ðŸ§¹ Cleanup Audit

on:
  workflow_dispatch:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  cleanup-audit:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install grimp networkx scikit-learn pytest pytest-cov coverage pyyaml
    
    - name: Run import graph analysis
      run: |
        python tools/inventory/import_graph.py
    
    - name: Run coverage analysis
      run: |
        python -m coverage run --source=stillme_core,stillme_ethical_core tools/inventory/feature_smoke.py || true
        coverage json -o artifacts/coverage.json || echo '{}' > artifacts/coverage.json
    
    - name: Run near-duplicate detection
      run: |
        python tools/inventory/near_dupe_detector.py || echo '{"near_dupe_clusters": {}}' > artifacts/near_dupes.json
    
    - name: Run redundant score analysis
      run: |
        python tools/inventory/redundant_score.py || echo 'path,inbound_imports,executed_lines,git_touches,days_since_last_change,looks_backup,in_registry,is_whitelisted,dupe_bucket,is_near_dupe,redundant_score' > artifacts/redundancy_report.csv
    
    - name: Check for backup files (STRICT GATES)
      run: |
        echo "ðŸ” Checking for backup files with STRICT GATES..."
        BACKUP_FILES=$(find . -name "*_backup.py" -o -name "*_old.py" -o -name "*_copy.py" -o -name "*_tmp.py" -o -name "*.py~" -o -name "*.py.save" | grep -v "_attic/" | grep -v ".git/" || true)
        if [ -n "$BACKUP_FILES" ]; then
          echo "âŒ FAIL: Found backup files (excluding _attic/):"
          echo "$BACKUP_FILES"
          echo "ðŸš« These files are NOT ALLOWED in the main codebase!"
          echo "ðŸ’¡ Move them to _attic/ or delete them permanently."
          exit 1
        else
          echo "âœ… No backup files found - STRICT GATES PASSED"
        fi
    
    - name: Check for new unused near-duplicates (ENHANCED)
      run: |
        echo "ðŸ” Checking for new unused near-duplicates with ENHANCED detection..."
        if [ -f "artifacts/baseline/near_dupes_baseline.json" ] && [ -f "artifacts/near_dupes.json" ]; then
          BASELINE_COUNT=$(jq '.near_dupe_clusters | length' artifacts/baseline/near_dupes_baseline.json 2>/dev/null || echo "0")
          CURRENT_COUNT=$(jq '.near_dupe_clusters | length' artifacts/near_dupes.json 2>/dev/null || echo "0")
          NEW_CLUSTERS=$((CURRENT_COUNT - BASELINE_COUNT))
          if [ "$NEW_CLUSTERS" -gt 0 ]; then
            echo "âš ï¸  WARN: Found $NEW_CLUSTERS new near-duplicate clusters!"
            echo "ðŸ“Š Baseline: $BASELINE_COUNT clusters, Current: $CURRENT_COUNT clusters"
            echo "ðŸ” Review artifacts/near_dupes.json for details"
          else
            echo "âœ… No new near-duplicate clusters found"
          fi
        else
          echo "âš ï¸  No baseline found for near-duplicate comparison"
        fi
    
    - name: Check for high-risk files
      run: |
        echo "ðŸ” Checking for high-risk files..."
        if [ -f "artifacts/redundancy_report.csv" ]; then
          HIGH_RISK=$(awk -F',' 'NR>1 && $11>=70 {print $1}' artifacts/redundancy_report.csv | head -10 || true)
          if [ -n "$HIGH_RISK" ]; then
            echo "âš ï¸  Found high-risk files (score >= 70):"
            echo "$HIGH_RISK"
            echo "Consider quarantining these files in next cleanup wave"
          else
            echo "âœ… No high-risk files found"
          fi
        fi
    
    - name: Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: cleanup-audit-artifacts
        path: |
          artifacts/
        retention-days: 30
    
    - name: Generate summary
      run: |
        echo "## ðŸ§¹ Cleanup Audit Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "artifacts/redundancy_report.csv" ]; then
          TOTAL_FILES=$(wc -l < artifacts/redundancy_report.csv)
          HIGH_RISK_COUNT=$(awk -F',' 'NR>1 && $11>=70 {count++} END {print count+0}' artifacts/redundancy_report.csv)
          echo "- **Total files analyzed:** $((TOTAL_FILES-1))" >> $GITHUB_STEP_SUMMARY
          echo "- **High-risk files (score >= 70):** $HIGH_RISK_COUNT" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "artifacts/near_dupes.json" ]; then
          CLUSTER_COUNT=$(jq '.near_dupe_clusters | length' artifacts/near_dupes.json 2>/dev/null || echo "0")
          echo "- **Near-duplicate clusters:** $CLUSTER_COUNT" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ðŸ“Š Artifacts Generated" >> $GITHUB_STEP_SUMMARY
        echo "- \`artifacts/import_inbound.json\`" >> $GITHUB_STEP_SUMMARY
        echo "- \`artifacts/coverage.json\`" >> $GITHUB_STEP_SUMMARY
        echo "- \`artifacts/near_dupes.json\`" >> $GITHUB_STEP_SUMMARY
        echo "- \`artifacts/redundancy_report.csv\`" >> $GITHUB_STEP_SUMMARY
